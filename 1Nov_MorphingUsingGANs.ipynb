{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BTP_15Sept.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aksh98/Attribute_Classification/blob/master/1Nov_MorphingUsingGANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "QqWNOGhiFcdD",
        "colab_type": "code",
        "outputId": "ddb5eaa1-51bb-42fe-9923-8174485bf491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K    100% |████████████████████████████████| 592.3MB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-0.3.0.post4\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.3.0.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch) (3.13)\n",
            "Collecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.3.0.post4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision) (3.13)\n",
            "Installing collected packages: pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jJfb0LHLrU27",
        "colab_type": "code",
        "outputId": "4a706043-351d-44ab-cca4-122693dc4bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "# !mkdir -p drive\n",
        "# !google-drive-ocamlfuse drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ln68XGr5Opk4",
        "colab_type": "code",
        "outputId": "ba4b47ad-714a-4488-ea6a-ca2ee6f86b0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd drive/My Drive/Colab Notebooks\n",
        "# %cd Colab Notebooks\n",
        "# %cd Gans_out\n",
        "# !ls\n",
        "# !mv 'Models (1)' Models\n",
        "# %cd ..\n",
        "# !ls\n",
        "# !ls | wc -l\n",
        "# %cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tIRSOjl1rk-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9eKNPIMr5IC",
        "colab_type": "code",
        "outputId": "25e7ce10-ae26-46a2-97c2-87e4ff862e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import scipy.io\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.colors import Normalize\n",
        "import os\n",
        "import pickle\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.utils as vutil\n",
        "print(\"Done\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Nfim3BZKYdm2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "  for extension in extensions: register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gMteEjvLr73r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "  for extension in extensions: register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions\n",
        "\n",
        "mini_batch_size = 16\n",
        "input_size = 64\n",
        "\n",
        "to_out = []\n",
        "\n",
        "def read_data(folder):\n",
        "  count = 0\n",
        "  dataset = []\n",
        "  for imgfile in os.listdir(folder):\n",
        "    img_data = cv2.imread(os.path.join(folder,imgfile))\n",
        "    if(img_data is not None):\n",
        "      img_data = cv2.resize(img_data,(64,64))\n",
        "      dataset.append(image_data)\n",
        "      count += 1\n",
        "    dataset = np.array(dataset)\n",
        "    return dataset\n",
        "  \n",
        "########################################################\n",
        "\n",
        "class RealAB(nn.Module):\n",
        "  \n",
        "  def __init__(self,in_channels):\n",
        "    super(RealAB, self).__init__()\n",
        "    #image1\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,8,kernel_size = 5,stride=1,padding=2),\n",
        "        nn.BatchNorm2d(8),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride = 2))\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(8,16,kernel_size = 5,stride = 1,padding=2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc = nn.Linear(16*16*16,64)\n",
        "    \n",
        "    #image2\n",
        "    self.layer11 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,8,kernel_size = 5,stride=1,padding=2),\n",
        "        nn.BatchNorm2d(8),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride = 2))\n",
        "    self.layer21 = nn.Sequential(\n",
        "        nn.Conv2d(8,16,kernel_size = 5,stride = 1,padding=2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc1 = nn.Linear(16*16*16,64)\n",
        "    \n",
        "  def forward(self,x, y):\n",
        "#     print(x.shape,y.shape)\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "#     print(out.shape)\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    out1 = self.layer11(y)\n",
        "    out1 = self.layer21(out1)\n",
        "#     print(\"out1sh-\",out1.shape)  # 16,16,16,16\n",
        "##### batch_size, channels_out * height_out * width_out\n",
        "    out1 = out1.view(out1.size(0),-1) \n",
        "    out1 = self.fc1(out1)\n",
        "#     print(\"out1\",out1.shape,out.shape)  # 16,64 \n",
        "    final = torch.cat((out,out1),1)\n",
        "#     print(\"fial\",final.shape) #16*128\n",
        "    return final\n",
        "    \n",
        "    \n",
        "    \n",
        "########################################################\n",
        "  \n",
        "class generator(nn.Module):\n",
        "  \n",
        "  def __init__(self, d = 16):\n",
        "    super(generator,self).__init__()\n",
        "    # in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "    self.inpAB = RealAB(in_channels = 3)\n",
        "    self.deconv1 = nn.ConvTranspose2d(128, d*8, 4, 1, 0)\n",
        "    self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
        "    self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "    self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
        "    self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "    self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
        "    self.deconv4 = nn.ConvTranspose2d(d*2, d  , 4, 2, 1)\n",
        "    self.deconv4_bn = nn.BatchNorm2d(d)\n",
        "    self.deconv5 = nn.ConvTranspose2d(d  , 3  , 4, 2, 1)\n",
        "    \n",
        "    for i in self.modules():\n",
        "      if(isinstance(i, nn.ConvTranspose2d)):\n",
        "        i.weight.data.normal_(0.0,0.2)\n",
        "        if(i.bias is not None):\n",
        "          i.bias.data.zero_()\n",
        "          \n",
        "  def forward(self,input1,input2): \n",
        "    x = self.inpAB(input1,input2)\n",
        "#     print(\"--->\",x.shape)\n",
        "    x = x.view(x.size(0),128,1,1)\n",
        "#     print(\"syappa -\",x.size())\n",
        "    x = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
        "    x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "    x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "    x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "    x = F.tanh(self.deconv5(x))\n",
        "    return x\n",
        "  \n",
        "class discriminator(nn.Module):\n",
        "  def __init__(self, d = 16):\n",
        "    super(discriminator,self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, d, 4, 2 , 1)\n",
        "    self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "    self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "    self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "    self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "    self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "    self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "    self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "    \n",
        "    for i in self.modules():\n",
        "      if( isinstance(i,nn.ConvTranspose2d)):\n",
        "        i.weight.data.normal_(0.0, 0.2)\n",
        "        if(i.bias is not None):\n",
        "          i.bias,data.zero_()\n",
        "          \n",
        "  def forward(self,input):\n",
        "    x = F.leaky_relu(self.conv1(input),0.2)\n",
        "    x = F.leaky_relu(self.conv2_bn(self.conv2(x)),0.2)\n",
        "    x = F.leaky_relu(self.conv3_bn(self.conv3(x)),0.2)\n",
        "    x = F.leaky_relu(self.conv4_bn(self.conv4(x)),0.2)\n",
        "    x = F.sigmoid(self.conv5(x))\n",
        "    \n",
        "    return x\n",
        "\n",
        "##############################################################\n",
        "  \n",
        "# model = TheModelClass(*args, **kwargs)\n",
        "# optimizer = TheOptimizerClass(*args, **kwargs)\n",
        "# checkpoint = torch.load(PATH)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "# model.eval()\n",
        "  \n",
        "##############################################################  \n",
        "  \n",
        "generator = generator(16)\n",
        "discriminator = discriminator(16)\n",
        "generator.cuda\n",
        "discriminator.cuda\n",
        "\n",
        "# criterionL1 = nn.L1Loss()\n",
        "#criterionMSE = nn.MSELoss()\n",
        "#criterionGAN = GANLoss()\n",
        "#criterionL1 = criterionL1.cuda()\n",
        "#criterionMSE = criterionMSE.cuda()\n",
        "#criterionGAN = criterionGAN.cuda()\n",
        "\n",
        "discriminator_optimizer = optim.Adam( discriminator.parameters(),lr = 0.0002)\n",
        "generator_optimizer = optim.Adam(generator.parameters(),lr = 0.0002)\n",
        "\n",
        "checkpointG = torch.load('/content/drive/My Drive/Colab Notebooks/Gans_out/Models/G.pth.tar') #\n",
        "checkpointD = torch.load('/content/drive/My Drive/Colab Notebooks/Gans_out/Models/D.pth.tar') #\n",
        "\n",
        "generator.load_state_dict(checkpointG['state_dict'])\n",
        "discriminator.load_state_dict(checkpointD['state_dict'])\n",
        "\n",
        "generator_optimizer.load_state_dict(checkpointG['optimizer_state_dict'])\n",
        "discriminator_optimizer.load_state_dict(checkpointD['optimizer_state_dict'])\n",
        "\n",
        "epoch = checkpointG['epoch']\n",
        "loss_G = checkpointG['loss']\n",
        "loss_D = checkpointD['loss']\n",
        "\n",
        "generator.eval()\n",
        "discriminator.eval()\n",
        "\n",
        "# epoch = 0\n",
        "# loss_D = []\n",
        "# loss_G = []\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "# criterion = criterion.cuda\n",
        "\n",
        "\n",
        "img_size = 64\n",
        "\n",
        "transform = transforms.Compose([ transforms.Resize((64,64)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5,0.5,0.5),std = (0.5,0.5,0.5))\n",
        "                              ])\n",
        "data_dir = '/content/drive/My Drive/Colab Notebooks/BiomProject/swapped/'\n",
        "dset = datasets.ImageFolder(data_dir,transform)\n",
        "train_loader = torch.utils.data.DataLoader(dset, batch_size=mini_batch_size, shuffle=True)\n",
        "\n",
        "gen_data = '/content/drive/My Drive/Colab Notebooks/lfw_aligned'\n",
        "genset = datasets.ImageFolder(gen_data,transform)\n",
        "gentrain_loader = torch.utils.data.DataLoader(genset, batch_size=mini_batch_size,shuffle=True)\n",
        "gentrain_loader2 = torch.utils.data.DataLoader(genset, batch_size=mini_batch_size,shuffle=True)\n",
        "\n",
        "print(\"Data Loaded\")\n",
        "\n",
        "exit()\n",
        "# print(\"Exitkebaad\")\n",
        "c = 0\n",
        "generator.zero_grad()\n",
        "\n",
        "################YAHA TK SAME HAI ######################\n",
        "\n",
        "#inputss for generator - swapped gndi images\n",
        "\n",
        "# train_target = torch.tensor(train['Target'].values)\n",
        "# input_for_generator =  Variable(gentrain_loader)\n",
        "# input_for_generator2 =  Variable(gentrain_loader2)\n",
        "\n",
        "# samples = generator(input_for_generator,input_for_generator2)\n",
        "print(\"Hurrah!! \")\n",
        "# samples = generator(gentrain_loader, gentrain_loader2)\n",
        "\n",
        "norm = Normalize()\n",
        "\n",
        "# fig = plt.figure(figsize = (4, 4))\n",
        "\n",
        "# gs = gridspec.GridSpec(4, 4)\n",
        "# gs.update(wspace=0.05, hspace=0.05)\n",
        "# for i in range(16):\n",
        "#   ax = plt.subplot(gs[i])\n",
        "#   plt.axis('off')\n",
        "#   ax.set_xticklabels([])\n",
        "#   ax.set_yticklabels([])\n",
        "#   ax.set_aspect('equal')\n",
        "#   plt.imshow((samples[i].cpu().data.numpy().transpose(1,2,0)+1)/2)\n",
        "# if (not os.path.exists('drive/My Drive/Colab Notebooks/Gans_out/output1')): # where to store outputs\n",
        "#   os.makedirs('drive/Colab Notebooks/Gans_out/output1')\n",
        "# plt.savefig('drive/My Drive/Colab Notebooks/Gans_out/output1/{}.png'.format(str(c),zfill(3)), bbox_inches = 'tight')\n",
        "# plt.close(fig)\n",
        "# c +=1\n",
        "# for x,_ in train_loader:\n",
        "#   pass\n",
        "# for i,_ in gentrain_loader:\n",
        "#   pass\n",
        "##############################################################\n",
        "#            Main algo - step1 \n",
        "##############################################################  \n",
        "\n",
        "\n",
        "for k in range(epoch,500):\n",
        "  discriminator.zero_grad()\n",
        "  print(\"k -> \",k)\n",
        "  for x_,y_,z_,in zip(train_loader,gentrain_loader,gentrain_loader2):\n",
        "    data = Variable(x_[0])\n",
        "    input_real = data\n",
        "    discriminator_real_out = discriminator(input_real)\n",
        "    # maybe a problem\n",
        "    discriminator_real_error = criterion(discriminator_real_out, Variable(torch.ones(mini_batch_size,1)))\n",
        "    \n",
        "    #send in the input ----\n",
        "    input_for_generator = Variable(y_[0])\n",
        "    input_for_generator2 = Variable(z_[0])\n",
        "    generator_gen_data = generator(input_for_generator,input_for_generator2).detach()\n",
        "    discriminator_fake_out = discriminator(generator_gen_data)\n",
        "    discriminator_fake_out = discriminator_fake_out.view(discriminator_fake_out.size(0),-1)\n",
        "    print(\"lol\",discriminator_fake_out.size(),Variable(torch.zeros(mini_batch_size,1)).size())\n",
        "    discriminator_fake_error = criterion(discriminator_fake_out,Variable(torch.zeros(mini_batch_size,1)))\n",
        "    \n",
        "    discriminator_total_error = discriminator_fake_error + discriminator_real_error\n",
        "    discriminator_total_error.backward()\n",
        "    discriminator_optimizer.step()\n",
        "    \n",
        "    # STEP 2 _ TRAIN GENERATOR \n",
        "    generator.zero_grad()\n",
        "    # send in the input -------\n",
        "    input_for_generator = Variable(y_[0])\n",
        "    input_for_generator2 = Variable(z_[0])\n",
        "    generator_out = generator(input_for_generator,input_for_generator2)\n",
        "    discriminator_out = discriminator(generator_out)\n",
        "    generator_error = criterion(discriminator_out, Variable(torch.ones(mini_batch_size,1)))\n",
        "    print(\".\",end='')\n",
        "    generator_error.backward()\n",
        "    generator_optimizer.step()\n",
        "  print('')  \n",
        "  print('Iteration{}  Disc_loss:{}, Gen_Loss: {}'.format(k,discriminator_total_error.data.numpy(),generator_error.data.numpy()))\n",
        "  loss_D.append(discriminator_total_error.data.numpy())\n",
        "  loss_G.append(generator_error.data.numpy())\n",
        "\n",
        "  torch.save({\n",
        "      'epoch':k, \n",
        "      'state_dict': generator.state_dict(),\n",
        "      'optimizer_state_dict': generator_optimizer.state_dict(),\n",
        "      'loss': loss_G, \n",
        "    },'/content/drive/My Drive/Colab Notebooks/Gans_out/Models/G.pth.tar')\n",
        "  torch.save({\n",
        "      'epoch': k, \n",
        "      'state_dict': discriminator.state_dict(),\n",
        "      'optimizer_state_dict': discriminator_optimizer.state_dict(),\n",
        "      'loss': loss_D,\n",
        "    },'/content/drive/My Drive/Colab Notebooks/Gans_out/Models/D.pth.tar')\n",
        "  print(\"Output stored\")\n",
        " \n",
        "##################################8############################\n",
        "#            Train the generator\n",
        "##############################################################  \n",
        "\n",
        "  # send the input again\n",
        "  for y_,z_ in zip(gentrain_loader,gentrain_loader2):\n",
        "    print(\"e-\",end='')\n",
        "    input_for_generator = Variable(y_[0])\n",
        "    input_for_generator2 = Variable(z_[0])\n",
        "    samples = generator(input_for_generator,input_for_generator2)\n",
        "    norm = Normalize()\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    gs = gridspec.GridSpec(4,4)\n",
        "    gs.update(wspace=0.05,hspace = 0.05)\n",
        "  \n",
        "    for i in range(16):\n",
        "      ax = plt.subplot(gs[i])\n",
        "      plt.axis('off')\n",
        "      ax.set_xticklabels([])\n",
        "      ax.set_yticklabels([])\n",
        "      ax.set_aspect('equal')\n",
        "      plt.imshow((samples[i].cpu().data.numpy().transpose(1, 2, 0)+1)/2)\n",
        "    plt.savefig('./Gans_out/output2/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
        "    c += 1\n",
        "    plt.close(fig)\n",
        "    \n",
        "#     input_for_generator = Variable(input_for_generator,)\n",
        "    samples = generator(input_for_generator,input_for_generator2).data.numpy()[:1]\n",
        "    norm = Normalize()\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    gs = gridspec.GridSpec(1, 1)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(norm(samples[0].transpose((1, 2, 0))))\n",
        "    if not os.path.exists('./Gans_out/output1/'):\n",
        "        os.makedirs('./Gans_out/output1/')\n",
        "\n",
        "    plt.savefig('./Gans_out/output1/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
        "    c += 1\n",
        "    plt.close(fig)\n",
        "\n",
        "arr = [loss_D,loss_G]\n",
        "pickle.dump(to_out,open(\"./Gans_out/Models/loss.dat\",\"wb\"))\n",
        "print(\"HAHAHAHAHAHHA\")\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4dAGtlZqlaXU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1rNC4IVBdYHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Example "
      ]
    },
    {
      "metadata": {
        "id": "xQoKxbCQlaLl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# import torch \n",
        "# import torch.nn as nn\n",
        "# import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# # Device configuration\n",
        "# # device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# # Hyper parameters\n",
        "# num_epochs = 5\n",
        "# num_classes = 10\n",
        "# batch_size = 100\n",
        "# learning_rate = 0.001\n",
        "\n",
        "# # MNIST dataset\n",
        "# train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "#                                            train=True, \n",
        "#                                            transform=transforms.ToTensor(),\n",
        "#                                            download=True)\n",
        "\n",
        "# test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "#                                           train=False, \n",
        "#                                           transform=transforms.ToTensor())\n",
        "\n",
        "# # Data loader\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "#                                            batch_size=batch_size, \n",
        "#                                            shuffle=True)\n",
        "\n",
        "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "#                                           batch_size=batch_size, \n",
        "#                                           shuffle=False)\n",
        "\n",
        "# # Convolutional neural network (two convolutional layers)\n",
        "# class ConvNet(nn.Module):\n",
        "#     def __init__(self, num_classes=10):\n",
        "#         super(ConvNet, self).__init__()\n",
        "#         self.layer1 = nn.Sequential(\n",
        "#             nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "#             nn.BatchNorm2d(16),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "#         self.layer2 = nn.Sequential(\n",
        "#             nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "#             nn.BatchNorm2d(32),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "#         self.fc = nn.Linear(7*7*32, num_classes)\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         out = self.layer1(x)\n",
        "#         out = self.layer2(out)\n",
        "#         out = out.reshape(out.size(0), -1)\n",
        "#         out = self.fc(out)\n",
        "#         return out\n",
        "\n",
        "# model = ConvNet(num_classes)\n",
        "\n",
        "# # Loss and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# # Train the model\n",
        "# total_step = len(train_loader)\n",
        "# for epoch in range(num_epochs):\n",
        "#     for i, (images, labels) in enumerate(train_loader):\n",
        "#         images = images\n",
        "#         labels = labels\n",
        "        \n",
        "#         # Forward pass\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels)\n",
        "        \n",
        "#         # Backward and optimize\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "        \n",
        "#         if (i+1) % 100 == 0:\n",
        "#             print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "#                    .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# # Test the model\n",
        "# model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "# with torch.no_grad():\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for images, labels in test_loader:\n",
        "#         images = images\n",
        "#         labels = labels\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# # Save the model checkpoint\n",
        "# torch.save(model.state_dict(), 'model.ckpt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "84W3VqvClf7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for x in range(10,250,10):\n",
        "  print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fCsa1iLkOS4y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2SKNFP6VYwsU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The backup"
      ]
    },
    {
      "metadata": {
        "id": "FJ55NIsBCVFq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mini_batch_size = 16\n",
        "input_size = 64\n",
        "\n",
        "to_out = []\n",
        "\n",
        "def read_data(folder):\n",
        "  count = 0\n",
        "  dataset = []\n",
        "  for imgfile in os.listdir(folder):\n",
        "    img_data = cv2.imread(os.path.join(folder,imgfile))\n",
        "    if(img_data is not None):\n",
        "      img_data = cv2.resize(img_data,(64,64))\n",
        "      dataset.append(image_data)\n",
        "      count += 1\n",
        "    dataset = np.array(dataset)\n",
        "    return dataset\n",
        "  \n",
        "########################################################\n",
        "\n",
        "class RealAB(nn.Module):\n",
        "  \n",
        "  def __init__(self,in_channels):\n",
        "    super(RealAB, self).__init__()\n",
        "    #image1\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,8,kernel_size = 5,stride=1,padding=2),\n",
        "        nn.BatchNorm2d(8),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride = 2))\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(8,16,kernel_size = 5,stride = 1,padding=2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc = nn.Linear(16*16*16,64)\n",
        "    \n",
        "    #image2\n",
        "    self.layer11 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,8,kernel_size = 5,stride=1,padding=2),\n",
        "        nn.BatchNorm2d(8),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride = 2))\n",
        "    self.layer21 = nn.Sequential(\n",
        "        nn.Conv2d(8,16,kernel_size = 5,stride = 1,padding=2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc1 = nn.Linear(16*16*16,64)\n",
        "    \n",
        "  def forward(self,x, y):\n",
        "#     print(x.shape,y.shape)\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "#     print(out.shape)\n",
        "    out = out.view(out.size(0),-1)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    out1 = self.layer11(y)\n",
        "    out1 = self.layer21(out1)\n",
        "#     print(\"out1sh-\",out1.shape)  # 16,16,16,16\n",
        "##### batch_size, channels_out * height_out * width_out\n",
        "    out1 = out1.view(out1.size(0),-1) \n",
        "    out1 = self.fc1(out1)\n",
        "#     print(\"out1\",out1.shape,out.shape)  # 16,64 \n",
        "    final = torch.cat((out,out1),1)\n",
        "#     print(\"fial\",final.shape) #16*128\n",
        "    return final\n",
        "    \n",
        "    \n",
        "    \n",
        "########################################################\n",
        "  \n",
        "class generator(nn.Module):\n",
        "  \n",
        "  def __init__(self, d = 16):\n",
        "    super(generator,self).__init__()\n",
        "    # in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "    self.inpAB = RealAB(in_channels = 3)\n",
        "    self.deconv1 = nn.ConvTranspose2d(128, d*8, 4, 1, 0)\n",
        "    self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
        "    self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "    self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
        "    self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "    self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
        "    self.deconv4 = nn.ConvTranspose2d(d*2, d  , 4, 2, 1)\n",
        "    self.deconv4_bn = nn.BatchNorm2d(d)\n",
        "    self.deconv5 = nn.ConvTranspose2d(d  , 3  , 4, 2, 1)\n",
        "    \n",
        "    for i in self.modules():\n",
        "      if(isinstance(i, nn.ConvTranspose2d)):\n",
        "        i.weight.data.normal_(0.0,0.2)\n",
        "        if(i.bias is not None):\n",
        "          i.bias.data.zero_()\n",
        "          \n",
        "  def forward(self,input1,input2): \n",
        "    x = self.inpAB(input1,input2)\n",
        "#     print(\"--->\",x.shape)\n",
        "    x = x.view(x.size(0),128,1,1)\n",
        "#     print(\"syappa -\",x.size())\n",
        "    x = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
        "    x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "    x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "    x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "    x = F.tanh(self.deconv5(x))\n",
        "    return x\n",
        "  \n",
        "class discriminator(nn.Module):\n",
        "  def __init__(self, d = 16):\n",
        "    super(discriminator,self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, d, 4, 2 , 1)\n",
        "    self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "    self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "    self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "    self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "    self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "    self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "    self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "    \n",
        "    for i in self.modules():\n",
        "      if( isinstance(i,nn.ConvTranspose2d)):\n",
        "        i.weight.data.normal_(0.0, 0.2)\n",
        "        if(i.bias is not None):\n",
        "          i.bias,data.zero_()\n",
        "          \n",
        "  def forward(self,input):\n",
        "    x = F.leaky_relu(self.conv1(input),0.2)\n",
        "    x = F.leaky_relu(self.conv2_bn(self.conv2(x)),0.2)\n",
        "    x = F.leaky_relu(self.conv3_bn(self.conv3(x)),0.2)\n",
        "    x = F.leaky_relu(self.conv4_bn(self.conv4(x)),0.2)\n",
        "    x = F.sigmoid(self.conv5(x))\n",
        "    \n",
        "    return x\n",
        "\n",
        "##############################################################\n",
        "  \n",
        "generator = generator(16)\n",
        "discriminator = discriminator(16)\n",
        "generator.cuda\n",
        "discriminator.cuda\n",
        "\n",
        "# criterionL1 = nn.L1Loss()\n",
        "#criterionMSE = nn.MSELoss()\n",
        "#criterionGAN = GANLoss()\n",
        "\n",
        "#criterionL1 = criterionL1.cuda()\n",
        "#criterionMSE = criterionMSE.cuda()\n",
        "#criterionGAN = criterionGAN.cuda()\n",
        "\n",
        "discriminator_optimizer = optim.Adam( discriminator.parameters(),lr = 0.0002)\n",
        "generator_optimizer = optim.Adam(generator.parameters(),lr = 0.0002)\n",
        "criterion = nn.BCELoss()\n",
        "# criterion = criterion.cuda\n",
        "\n",
        "\n",
        "img_size = 64\n",
        "\n",
        "transform = transforms.Compose([ transforms.Resize((64,64)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5,0.5,0.5),std = (0.5,0.5,0.5))\n",
        "                              ])\n",
        "data_dir = '/content/drive/My Drive/Colab Notebooks/BiomProject/swapped/'\n",
        "dset = datasets.ImageFolder(data_dir,transform)\n",
        "train_loader = torch.utils.data.DataLoader(dset, batch_size=mini_batch_size, shuffle=True)\n",
        "\n",
        "gen_data = '/content/drive/My Drive/Colab Notebooks/lfw_aligned'\n",
        "genset = datasets.ImageFolder(gen_data,transform)\n",
        "gentrain_loader = torch.utils.data.DataLoader(genset, batch_size=mini_batch_size,shuffle=True)\n",
        "gentrain_loader2 = torch.utils.data.DataLoader(genset, batch_size=mini_batch_size,shuffle=True)\n",
        "\n",
        "print(\"Data Loaded\")\n",
        "\n",
        "exit()\n",
        "# print(\"Exitkebaad\")\n",
        "c = 0\n",
        "generator.zero_grad()\n",
        "\n",
        "################YAHA TK SAME HAI ######################\n",
        "\n",
        "#inputss for generator - swapped gndi images\n",
        "\n",
        "# train_target = torch.tensor(train['Target'].values)\n",
        "# input_for_generator =  Variable(gentrain_loader)\n",
        "# input_for_generator2 =  Variable(gentrain_loader2)\n",
        "\n",
        "# samples = generator(input_for_generator,input_for_generator2)\n",
        "print(\"Hurrah!! \")\n",
        "# samples = generator(gentrain_loader, gentrain_loader2)\n",
        "\n",
        "norm = Normalize()\n",
        "\n",
        "# fig = plt.figure(figsize = (4, 4))\n",
        "\n",
        "# gs = gridspec.GridSpec(4, 4)\n",
        "# gs.update(wspace=0.05, hspace=0.05)\n",
        "# for i in range(16):\n",
        "#   ax = plt.subplot(gs[i])\n",
        "#   plt.axis('off')\n",
        "#   ax.set_xticklabels([])\n",
        "#   ax.set_yticklabels([])\n",
        "#   ax.set_aspect('equal')\n",
        "#   plt.imshow((samples[i].cpu().data.numpy().transpose(1,2,0)+1)/2)\n",
        "# if (not os.path.exists('drive/My Drive/Colab Notebooks/Gans_out/output1')): # where to store outputs\n",
        "#   os.makedirs('drive/Colab Notebooks/Gans_out/output1')\n",
        "# plt.savefig('drive/My Drive/Colab Notebooks/Gans_out/output1/{}.png'.format(str(c),zfill(3)), bbox_inches = 'tight')\n",
        "# plt.close(fig)\n",
        "# c +=1\n",
        "\n",
        "loss_D = []\n",
        "loss_G = []\n",
        "\n",
        "# for x,_ in train_loader:\n",
        "#   pass\n",
        "\n",
        "# for i,_ in gentrain_loader:\n",
        "#   pass\n",
        "##############################################################\n",
        "#            Main algo - step1 \n",
        "##############################################################  \n",
        "\n",
        "\n",
        "for k in range(500):\n",
        "  discriminator.zero_grad()\n",
        "  print(\"k -> \",k)\n",
        "  for x_,y_,z_,in zip(train_loader,gentrain_loader,gentrain_loader2):\n",
        "    data = Variable(x_[0])\n",
        "    input_real = data\n",
        "    discriminator_real_out = discriminator(input_real)\n",
        "    # maybe a problem\n",
        "    discriminator_real_error = criterion(discriminator_real_out, Variable(torch.ones(mini_batch_size,1)))\n",
        "    \n",
        "    #send in the input ----\n",
        "    input_for_generator = Variable(y_[0])\n",
        "    input_for_generator2 = Variable(z_[0])\n",
        "    generator_gen_data = generator(input_for_generator,input_for_generator2).detach()\n",
        "    discriminator_fake_out = discriminator(generator_gen_data)\n",
        "    discriminator_fake_out = discriminator_fake_out.view(discriminator_fake_out.size(0),-1)\n",
        "    print(\"lol\",discriminator_fake_out.size(),Variable(torch.zeros(mini_batch_size,1)).size())\n",
        "    discriminator_fake_error = criterion(discriminator_fake_out,Variable(torch.zeros(mini_batch_size,1)))\n",
        "    \n",
        "    discriminator_total_error = discriminator_fake_error + discriminator_real_error\n",
        "    discriminator_total_error.backward()\n",
        "    discriminator_optimizer.step()\n",
        "    \n",
        "    # STEP 2 _ TRAIN GENERATOR \n",
        "    generator.zero_grad()\n",
        "    # send in the input -------\n",
        "    input_for_generator = Variable(y_[0])\n",
        "    input_for_generator2 = Variable(z_[0])\n",
        "    generator_out = generator(input_for_generator,input_for_generator2)\n",
        "    discriminator_out = discriminator(generator_out)\n",
        "    generator_error = criterion(discriminator_out, Variable(torch.ones(mini_batch_size,1)))\n",
        "    print(\".\",end='')\n",
        "    generator_error.backward()\n",
        "    generator_optimizer.step()\n",
        "  print('')  \n",
        "  print('Iteration{}  Disc_loss:{}, Gen_Loss: {}'.format(k,discriminator_total_error.data.numpy(),generator_error.data.numpy()))\n",
        "  loss_D.append(discriminator_total_error.data.numpy())\n",
        "  loss_G.append(generator_error.data.numpy())\n",
        "#   torch.save(generator.state_dict(), \"./Gans_out/Models/G_{0:03}.pwf\".format(k))\n",
        "#   torch.save(discriminator.state_dict(), \"./Gans_out/Models/D_{0:03}.pwf\".format(k))\n",
        "    \n",
        "  torch.save({\n",
        "      'epoch':k, \n",
        "      'state_dict': generator.state_dict(),\n",
        "    },'/content/drive/My Drive/Colab Notebooks/Gans_out/Models/G.pth.tar')\n",
        "  torch.save({\n",
        "      'epoch': k, \n",
        "      'state_dict': discriminator.state_dict(),\n",
        "    },'/content/drive/My Drive/Colab Notebooks/Gans_out/Models/D.pth.tar')\n",
        "  print(\"Output stored\")\n",
        " \n",
        "##################################8############################\n",
        "#            Train the generator\n",
        "##############################################################  \n",
        "\n",
        "  # send the input again\n",
        "  for y_,z_ in zip(gentrain_loader,gentrain_loader2):\n",
        "    print(\"e-\",end='')\n",
        "    input_for_generator = Variable(y_[0])\n",
        "    input_for_generator2 = Variable(z_[0])\n",
        "    samples = generator(input_for_generator,input_for_generator2)\n",
        "    norm = Normalize()\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    gs = gridspec.GridSpec(4,4)\n",
        "    gs.update(wspace=0.05,hspace = 0.05)\n",
        "  \n",
        "    for i in range(16):\n",
        "      ax = plt.subplot(gs[i])\n",
        "      plt.axis('off')\n",
        "      ax.set_xticklabels([])\n",
        "      ax.set_yticklabels([])\n",
        "      ax.set_aspect('equal')\n",
        "      plt.imshow((samples[i].cpu().data.numpy().transpose(1, 2, 0)+1)/2)\n",
        "    plt.savefig('./Gans_out/output2/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
        "    c += 1\n",
        "    plt.close(fig)\n",
        "    \n",
        "#     input_for_generator = Variable(input_for_generator,)\n",
        "    samples = generator(input_for_generator,input_for_generator2).data.numpy()[:1]\n",
        "    norm = Normalize()\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    gs = gridspec.GridSpec(1, 1)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(norm(samples[0].transpose((1, 2, 0))))\n",
        "    if not os.path.exists('./Gans_out/output1/'):\n",
        "        os.makedirs('./Gans_out/output1/')\n",
        "\n",
        "    plt.savefig('./Gans_out/output1/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
        "    c += 1\n",
        "    plt.close(fig) \n",
        "\n",
        "arr = [loss_D,loss_G]\n",
        "pickle.dump(to_out,open(\"./Gans_out/Models/loss.dat\",\"wb\"))\n",
        "print(\"HAHAHAHAHAHHA\")\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9JMIKBwByhPQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mini_batch_size = 128\n",
        "input_size = 100\n",
        "\n",
        "to_out = []\n",
        "\n",
        "def read_data(folder):\n",
        "  count = 0\n",
        "  dataset = []\n",
        "  for imgfile in os.listdir(folder):\n",
        "    img_data = cv2.imread(os.path.join(folder,imgfile))\n",
        "    if(img_data is not None):\n",
        "      img_data = cv2.resize(img_data,(250,250))\n",
        "      dataset.append(image_data)\n",
        "      count += 1\n",
        "    dataset = np.array(dataset)\n",
        "    return dataset\n",
        "  \n",
        "########################################################\n",
        "\n",
        "class RealAB(nn.Module):\n",
        "  \n",
        "  def __init__(self,in_channels):\n",
        "    super(RealAB, self).__init__()\n",
        "    \n",
        "    #image1\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,16,kernel_size = 5,stride=1,padding=2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride = 2))\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(16,32,kernel_size = 5,stride = 1,padding=2),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc = nn.Linear(7*7*32,100)\n",
        "    \n",
        "    #image2\n",
        "    self.layer11 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,16,kernel_size = 5,stride=1,padding=2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride = 2))\n",
        "    self.layer21 = nn.Sequential(\n",
        "        nn.Conv2d(16,32,kernel_size = 5,stride = 1,padding=2),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc1 = nn.Linear(7*7*32,100)\n",
        "    \n",
        "  def forward(self,x, y):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.reshape(out.size(0),-1)\n",
        "    out = self.fc(out)\n",
        "    \n",
        "    out1 = self.layer11(y)\n",
        "    out1 = self.layer21(out1)\n",
        "    out1 = out1.reshape(out1.size(0),-1)\n",
        "    out1 = self.fc1(out1)\n",
        "    \n",
        "    final = torch.cat((out,out1),1)\n",
        "    return final\n",
        "    \n",
        "    \n",
        "    \n",
        "########################################################\n",
        "  \n",
        "class generator(nn.Module):\n",
        "  \n",
        "  def __init__(self, d = 128):\n",
        "    super(generator,self).__init__()\n",
        "    # in_channels, out_channels, kernel_size, stride=1, padding=0\n",
        "    self.inpAB = RealAB(in_channels = 3)\n",
        "    self.deconv1 = nn.ConvTranspose2d(100, d*8, 4, 1, 0)\n",
        "    self.deconv1_bn = nn.BatchNorm2d(d*8)\n",
        "    self.deconv2 = nn.ConvTranspose2d(d*8, d*4, 4, 2, 1)\n",
        "    self.deconv2_bn = nn.BatchNorm2d(d*4)\n",
        "    self.deconv3 = nn.ConvTranspose2d(d*4, d*2, 4, 2, 1)\n",
        "    self.deconv3_bn = nn.BatchNorm2d(d*2)\n",
        "    self.deconv4 = nn.ConvTranspose2d(d*2, d  , 4, 2, 1)\n",
        "    self.deconv4_bn = nn.BatchNorm2d(d)\n",
        "    self.deconv5 = nn.ConvTranspose2d(d  , 3  , 4, 2, 1)\n",
        "    \n",
        "    for i in self.modules():\n",
        "      if(isinstance(i, nn.ConvTranspose2d)):\n",
        "        i.weight.data.normal_(0.0,0.2)\n",
        "        if(i.bias is not None):\n",
        "          i.bias.data.zero_()\n",
        "          \n",
        "  def forward(self,input1,input2): \n",
        "    x = self.inpAB(input1,input2)\n",
        "    x = F.relu(self.deconv1_bn(self.deconv1(x)))\n",
        "    x = F.relu(self.deconv2_bn(self.deconv2(x)))\n",
        "    x = F.relu(self.deconv3_bn(self.deconv3(x)))\n",
        "    x = F.relu(self.deconv4_bn(self.deconv4(x)))\n",
        "    x = F.tanh(self.deconv5(x))\n",
        "    return x\n",
        "  \n",
        "class discriminator(nn.Module):\n",
        "  def __init__(self, d = 128 ):\n",
        "    super(discriminator,self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(3, d, 4, 2 , 1)\n",
        "    self.conv2 = nn.Conv2d(d, d*2, 4, 2, 1)\n",
        "    self.conv2_bn = nn.BatchNorm2d(d*2)\n",
        "    self.conv3 = nn.Conv2d(d*2, d*4, 4, 2, 1)\n",
        "    self.conv3_bn = nn.BatchNorm2d(d*4)\n",
        "    self.conv4 = nn.Conv2d(d*4, d*8, 4, 2, 1)\n",
        "    self.conv4_bn = nn.BatchNorm2d(d*8)\n",
        "    self.conv5 = nn.Conv2d(d*8, 1, 4, 1, 0)\n",
        "    \n",
        "    for i in self.modules():\n",
        "      if( isinstance(i,nn.ConvTranspose2d)):\n",
        "        i.weight.data.normal_(0.0, 0.2)\n",
        "        if(i.bias is not None):\n",
        "          i.bias,data.zero_()\n",
        "          \n",
        "  def forward(self,input):\n",
        "    x = F.leaky_relu(self.conv1(input),0.2)\n",
        "    x = F.leaky_relu(self.conv2_bn(self.conv2(x)),0.2)\n",
        "    x = F.leaky_relu(self.conv3_bn(self.conv3(x)),0.2)\n",
        "    x = F.leaky_relu(self.conv4_bn(self.conv4(x)),0.2)\n",
        "    x = F.sigmoid(self.conv5(x))\n",
        "    \n",
        "    return x\n",
        "\n",
        "##############################################################\n",
        "  \n",
        "generator = generator(128)\n",
        "discriminator = discriminator(128)\n",
        "# generator.cuda()\n",
        "# discriminator.cuda()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "#criterionL1 = nn.L1Loss()\n",
        "#criterionMSE = nn.MSELoss()\n",
        "#criterionGAN = GANLoss()\n",
        "\n",
        "#criterionL1 = criterionL1.cuda()\n",
        "#criterionMSE = criterionMSE.cuda()\n",
        "#criterionGAN = criterionGAN.cuda()\n",
        "\n",
        "discriminator_optimizer = optim.Adam( discriminator.parameters(),lr = 0.0002)\n",
        "generator_optimizer = optim.Adam(generator.parameters(),lr = 0.0002)\n",
        "\n",
        "\n",
        "img_size = 250\n",
        "\n",
        "transform = transforms.Compose([ transforms.Resize((250,250)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5,0.5,0.5),std = (0.5,0.5,0.5))\n",
        "                              ])\n",
        "data_dir = '/content/drive/My Drive/Colab Notebooks/BiomProject/swapped/'\n",
        "dset = datasets.ImageFolder(data_dir,transform)\n",
        "train_loader = torch.utils.data.DataLoader(dset, batch_size=128, shuffle=True)\n",
        "\n",
        "gen_data = '/content/drive/My Drive/Colab Notebooks/lfw_aligned'\n",
        "genset = datasets.ImageFolder(gen_data,transform)\n",
        "gentrain_loader = torch.utils.data.DataLoader(genset, batch_size=128,shuffle=True)\n",
        "gentrain_loader2 = torch.utils.data.DataLoader(genset, batch_size=128,shuffle=True)\n",
        "\n",
        "print(\"Data Loaded\")\n",
        "\n",
        "exit()\n",
        "\n",
        "c = 0\n",
        "generator.zero_grad()\n",
        "\n",
        "################\n",
        "#inputss for generator - swapped gndi images\n",
        "\n",
        "# train_target = torch.tensor(train['Target'].values)\n",
        "# input_for_generator =  Variable(gentrain_loader)\n",
        "# input_for_generator2 =  Variable(gentrain_loader2)\n",
        "\n",
        "# samples = generator(input_for_generator,input_for_generator2)\n",
        "print(\"Hurrah!! \")\n",
        "# samples = generator(gentrain_loader, gentrain_loader2)\n",
        "\n",
        "norm = Normalize()\n",
        "\n",
        "# fig = plt.figure(figsize = (4, 4))\n",
        "\n",
        "# gs = gridspec.GridSpec(4, 4)\n",
        "# gs.update(wspace=0.05, hspace=0.05)\n",
        "print(\"YOLO !!!! \")\n",
        "# for i in range(16):\n",
        "#   ax = plt.subplot(gs[i])\n",
        "#   plt.axis('off')\n",
        "#   ax.set_xticklabels([])\n",
        "#   ax.set_yticklabels([])\n",
        "#   ax.set_aspect('equal')\n",
        "#   plt.imshow((samples[i].cpu().data.numpy().transpose(1,2,0)+1)/2)\n",
        "# if (not os.path.exists('drive/My Drive/Colab Notebooks/Gans_out/output1')): # where to store outputs\n",
        "#   os.makedirs('drive/Colab Notebooks/Gans_out/output1')\n",
        "# plt.savefig('drive/My Drive/Colab Notebooks/Gans_out/output1/{}.png'.format(str(c),zfill(3)), bbox_inches = 'tight')\n",
        "# plt.close(fig)\n",
        "# c +=1\n",
        "\n",
        "print(\"Output stored\")\n",
        "loss_D = []\n",
        "loss_G = []\n",
        "\n",
        "# for x,_ in train_loader:\n",
        "#   pass\n",
        "\n",
        "# for i,_ in gentrain_loader:\n",
        "#   pass\n",
        "##############################################################\n",
        "#            Main algo - step1 \n",
        "##############################################################  \n",
        "\n",
        "\n",
        "for k in range(1):\n",
        "  discriminator.zero_grad()\n",
        "\n",
        "  for x_,y_,z_,in zip(train_loader,gentrain_loader,gentrain_loader2):\n",
        "    data = Variable(x_[0])\n",
        "    input_real = data\n",
        "    discriminator_real_out = discriminator(input_real)\n",
        "    # maybe a problem\n",
        "    discriminator_real_error = criterion(discriminator_real_out, Variable(torch.ones(mini_batch_size,1)))\n",
        "    \n",
        "    #send in the input ----\n",
        "    input_for_generator = Variable(y_[0])\n",
        "    input_for_generator2 = Variable(z_[0])\n",
        "    generator_gen_data = generator(input_for_generator,input_for_generator2).detach()\n",
        "    discriminator_fake_out = discriminator(generator_gen_data)\n",
        "    discriminator_fake_error = criterion(discriminator_fake_out,Variable(torch.zeros(mini_batch_size,1)))\n",
        "    \n",
        "    discriminator_total_error = discriminator_fake_error + discriminator_real_error\n",
        "    discriminator_total_error.backward()\n",
        "    discriminator_optimiser.step()\n",
        "    \n",
        "    # STEP 2 _ GENERATE IMAGES\n",
        "    generator.zero_grad()\n",
        "    # send in the input -------\n",
        "    input_for_generator = Variable(y_[0])\n",
        "    input_for_generator2 = Variable(z_[0])\n",
        "    generator_out = generator(input_for_generator,input_for_generator2)\n",
        "    discriminator_out = discriminator(generator_out)\n",
        "    generator_error = criterion(discriminator_out, Variable(torch.ones(mini_batch_size,1)))\n",
        "\n",
        "    generator_error.backward()\n",
        "    generator_optimiser.step()\n",
        "    \n",
        "  print('Iteration{}  Disc_loss:{}, Gen_Loss: {}'.format(k,discriminator_total_error.data.numpy(),generator_error.data.numpy()))\n",
        "  loss_D.append(discriminator_total_error.data.numpy())\n",
        "  loss_G.append(generator_error.data.numpy())\n",
        "  \n",
        "  torch.save({\n",
        "      'epoch':k, \n",
        "      'state_dict': generator.state_dict(),\n",
        "    },'drive/My Drive/Colab Notebooks/Gans_out/Models/G.pth.tar')\n",
        "  torch.save({\n",
        "      'epoch': k, \n",
        "      'state_dict': discriminator.state_dict(),\n",
        "    },'drive/My Drive/Colab Notebooks/Gans_out/Models/D.pth.tar')\n",
        "  \n",
        "##############################################################\n",
        "#            PLOT THE IMAGES\n",
        "##############################################################  \n",
        "\n",
        "  # send the input again\n",
        "  for y_,z_ in zip(gentrain_loader,gentrain_loader2):\n",
        "    input_for_generator = Veriable(y_)\n",
        "    input_for_generator2 = Veriable(z_)\n",
        "    samples = generator(input_for_generator,input_for_generator2)\n",
        "    norm = Normalize()\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "    gs = gridspec.GridSpec(4,4)\n",
        "    gs.update(wspace=0.05,hspace = 0.05)\n",
        "  \n",
        "#   for i in range(16):\n",
        "#     ax = plt.subplot(gs[i])\n",
        "#     plt.axis('off')\n",
        "#     ax.set_xticklabels([])\n",
        "#     ax.set_yticklabels([])\n",
        "#     ax.set_aspect('equal')\n",
        "#     plt.imshow((samples[i].cpu().data.numpy().transpose(1, 2, 0)+1)/2)\n",
        "#   if not os.path.exists('drive/My Drive/Colab Notebooks/Gans_out/output2/'):\n",
        "#       os.makedirs('drive/Colab Notebooks/Gans_out/output2/')\n",
        "    plt.savefig('drive/My Drive/Colab Notebooks/Gans_out/output2/{}.png'.format(str(c).zfill(3)), bbox_inches='tight')\n",
        "    c += 1\n",
        "    plt.close(fig)\n",
        "    break\n",
        "\n",
        "arr = [loss_D,loss_G]\n",
        "pickle.dump(to_out,open(\"drive/My Drive/Colab Notebooks/Gans_out/Models/loss.dat\",\"wb\"))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hs-BMDf3hnfN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}