{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7a335f18289e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 \n",
    "# from sklearn import svm\n",
    "import shutil\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imutils import face_utils\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# folders = os.listdir(\"lfw\")\n",
    "# # print(folders)\n",
    "# # images = \n",
    "# print(len(folders))\n",
    "# count = 0\n",
    "# for folder in folders:\n",
    "# #     print(folder)\n",
    "\n",
    "#     if(folder!='.DS_Store'):\n",
    "#         folder = os.path.join(\"lfw\",folder)\n",
    "#         images = os.listdir(folder)\n",
    "#         for image in images:\n",
    "#             if(image!='.DS_Store'):\n",
    "#                 count+=1\n",
    "# #                 print(image)\n",
    "#                 src = os.path.join(\"/Users/akarsha/Downloads\",folder)\n",
    "#                 src = os.path.join(src,image)\n",
    "#                 dest = os.path.join(\"/Users/akarsha/Downloads/lfw_A\",image)\n",
    "#                 shutil.move(src,dest)\n",
    "#                 img = cv2.imread(image)\n",
    "# #                 cv2.imwrite(image,img)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertion(arr,i):\n",
    "    if(float(arr[i]) > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "FACIAL_LANDMARKS_IDXS = OrderedDict([\n",
    "\t(\"mouth\", (48, 68)),\n",
    "\t(\"right_eyebrow\", (17, 22)),\n",
    "\t(\"left_eyebrow\", (22, 27)),\n",
    "\t(\"right_eye\", (36, 42)),\n",
    "\t(\"left_eye\", (42, 48)),\n",
    "\t(\"nose\", (27, 35)),\n",
    "\t(\"jaw\", (0, 17))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047\n",
      "Matrix size 1047 74\n"
     ]
    }
   ],
   "source": [
    "x = np.loadtxt('btpdataset.txt',delimiter = '\\n',dtype=np.str)\n",
    "print(len(x))\n",
    "array = []\n",
    "h, w = 1047, 74\n",
    "matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "#----ATTRIBUTES CONSIDERED------\n",
    "white = []\n",
    "noEyewear = []\n",
    "sunglasses = []\n",
    "smiling = []\n",
    "visible_forehead = []\n",
    "#---------------------\n",
    "\n",
    "smile = []\n",
    "images = []\n",
    "glasses = []\n",
    "# we have 74 attributes - and 2 for the name of the person\n",
    "for i in range(len(x)):\n",
    "    arr = x[i].split() # 76 = len(arr)\n",
    "    \n",
    "    name_len = len(arr)-74\n",
    "# Adding name to matrix\n",
    "    la = arr[0]+\"_\"\n",
    "    for l in range(1,name_len):\n",
    "        la += arr[l]+\"_\"\n",
    "    if(float(arr[name_len]) > 9):\n",
    "        la += \"00\" + arr[name_len]+\".ppm\"\n",
    "    else:\n",
    "        la += \"000\" + arr[name_len] +\".ppm\"\n",
    "    matrix[i][0] = la\n",
    "    images.append(la)\n",
    "    \n",
    "    for j in range(name_len,len(arr)-1):\n",
    "        if(float(arr[j+1]) > 0): matrix[i][j-name_len+1] = 1 \n",
    "        else: matrix[i][j-name_len+1] = 0\n",
    "        insertion(arr,j+1)\n",
    "print(\"Matrix size\",len(matrix),len(matrix[0]))\n",
    "# #     male.append(float(arr[name_len+1]))\n",
    "#     white.append(insertion(arr,name_len+3))\n",
    "# #     black_hair.append(float(arr[name_len+9]))\n",
    "#     smiling.append(insertion(arr,name_len+18))\n",
    "#     noEyewear.append(insertion(arr,name_len+14))\n",
    "#     sunglasses.append(insertion(arr,name_len+16))\n",
    "#     visible_forehead.append(insertion(arr,name_len+32))\n",
    "#     print (la)\n",
    "# print(noEyewear)\n",
    "\n",
    "\n",
    "\n",
    "# images = os.listdir(\"lfw_A\")\n",
    "# Mat img_mat(len(images),250*250,CV_32FC3)\n",
    "# for img in images:\n",
    "#     imgpath = os.path.join(\"/Users/akarsha/Downloads/lfw_A\",img)\n",
    "#     image = cv2.imread(imgpath)\n",
    "#     Mat reshape_img = \n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "# 1 - choose all pixels on the face and let the classifier choose \n",
    "# try with using local feature options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Possible attributes to be classifiedd\n",
    "# No Eyewear\n",
    "# No sunglasses\n",
    "# Smiling\n",
    "# Frowning\n",
    "# Mouth wide open\n",
    "\n",
    "# Improvements - Consider specific facial regions - consider lfw crop dataset - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face_cascade = cv2.CascadeClassifier('/Users/akarsha/anaconda/lib/python3.6/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "# eye_cascade = cv2.CascadeClassifier('/Users/akarsha/anaconda/lib/python3.6/site-packages/cv2/data/haarcascade_eye.xml')\n",
    "# smile_cascade = cv2.CascadeClassifier(\"/Users/akarsha/anaconda/lib/python3.6/site-packages/cv2/data/haarcascade_smile.xml\")\n",
    "\n",
    "\n",
    "#-------------------EYES for 1 image ! ----------------------\n",
    "\n",
    "# img = cv2.imread(\"Adriana_Perez_Navarro_0001.jpg\")\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# print(smile_cascade.empty)\n",
    "# print(face_cascade.empty)\n",
    "\n",
    "# faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "# print(faces)\n",
    "# for (x,y,w,h) in faces:\n",
    "#     cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#     print(x,y,w,h)\n",
    "#     roi_gray = gray[y:y+h, x:x+w]\n",
    "#     roi_color = img[y:y+h, x:x+w]\n",
    "#     eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#     print(eyes)\n",
    "#     if(len(eyes)>0):\n",
    "#         print(\"hola\")\n",
    "#     else:\n",
    "#         print(\"lola\")\n",
    "#     for (ex,ey,ew,eh) in eyes:\n",
    "#         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "#         print(ex,ey,ew,eh)\n",
    "#     smiles = smile_cascade.detectMultiScale(roi_gray,scaleFactor= 1.7,minNeighbors=22,minSize=(25, 25),flags=cv2.CASCADE_SCALE_IMAGE) \n",
    "#     for (x, y, w, h) in smiles:\n",
    "#         print( \"Found\", len(smiles), \"smiles!\")\n",
    "#         cv2.rectangle(roi_color, (x, y), (x+w, y+h), (255, 0, 0), 1)\n",
    "\n",
    "\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "#----------------------------------------------------------\n",
    "\n",
    "# images = os.listdir(\"lfw_A\")\n",
    "# Mat img_mat(len(images),250*250,CV_32FC3)\n",
    "\n",
    "# for img in images: # 523 in this case\n",
    "#     imgpath = os.path.join(\"/Users/akarsha/Downloads/BTP/lfw_crop_A\",img)\n",
    "#     image = cv2.imread(imgpath)\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # faces returns an array with \n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "#     if(len(faces)>1):\n",
    "#         print(img)\n",
    "#     if(len(faces)==0):\n",
    "#         print(img,\"LOLOLOL\")\n",
    "#     for (x,y,w,h) in faces:\n",
    "\n",
    "#     cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "#     roi_gray = gray[y:y+h, x:x+w]\n",
    "#     roi_color = image[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "#     eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#     if(len(eyes)>0):\n",
    "#         glasses.append(1)\n",
    "#     else:\n",
    "#         glasses.append(0)\n",
    "#     smiles = smile_cascade.detectMultiScale(roi_gray,scaleFactor= 1.7,minNeighbors=22,minSize=(25, 25))\n",
    "#     if(len(smiles)>0):\n",
    "#         smile.append(1)\n",
    "#     else:\n",
    "#         smile.append(0)\n",
    "        \n",
    "# counteye = 0\n",
    "# countsmile = 0\n",
    "# print(\"smil\",len(smiling),len(smile),len(noEyewear),len(glasses))\n",
    "# for i in range(0,len(noEyewear)):\n",
    "#     if(noEyewear[i] >= 0 and glasses[i] == 1):\n",
    "#         counteye = counteye+1;\n",
    "#     if(noEyewear[i] < 0 and glasses[i] == 0):\n",
    "#         counteye= counteye+1;\n",
    "# print(float(counteye)/float(len(noEyewear)))\n",
    "\n",
    "    \n",
    "\n",
    "# for i in range(0,len(smiling)):\n",
    "#     if(smiling[i] >= 0 and smile[i] == 1):\n",
    "#         countsmile= countsmile+1;\n",
    "#     if(smiling[i] < 0 and smile[i] == 0):\n",
    "#         countsmile= countsmile+1;\n",
    "# print(float(countsmile)/float(len(smiling)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tips by PhD....\n",
    "\n",
    "# io.loadmat \n",
    "# io.savemat \n",
    "# save as mat file\n",
    "# search image by the imagename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dated - 11 - 3 - 18\n",
    "# white, noEyewear, sunglasses, smiling, visible_forehead \n",
    "# Image shape - (64,64,3)\n",
    "\n",
    "# face_cascade = cv2.CascadeClassifier('/Users/akarsha/anaconda/lib/python3.6/site-packages/cv2/data/haarcascade_frontalface_default.xml')\n",
    "# eye_cascade = cv2.CascadeClassifier('/Users/akarsha/anaconda/lib/python3.6/site-packages/cv2/data/haarcascade_eye.xml')\n",
    "# smile_cascade = cv2.CascadeClassifier(\"/Users/akarsha/anaconda/lib/python3.6/site-packages/cv2/data/haarcascade_smile.xml\")\n",
    "\n",
    "i = 0\n",
    "img_arr = []\n",
    "for img in images: # 523 in this case\n",
    "    \n",
    "    imgpath = os.path.join(\"/Users/akarsha/Downloads/BTP/lfw_crop_A\",img)\n",
    "#     imgpath = os.path.join(\"/Users/akarsha/Downloads/BTP/lfw_A\",img)\n",
    "    image = cv2.imread(imgpath,0) \n",
    "#     print(np.shape(image))\n",
    "    # Greyscale image used  here..\n",
    "    \n",
    "# print(np.shape(image))\n",
    "    if(image is None):\n",
    "        print(\"No Image loaded\")\n",
    "        print(img)\n",
    "        \n",
    "    else:\n",
    "        img_arr.append(np.reshape(image,4096))\n",
    "#         img_arr.append(np.reshape(image,62500))\n",
    "\n",
    "\n",
    "\n",
    "# print(np.shape(img_arr))  --- # 1047 * 4096 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yupzie\n",
      "0.690751445087\n"
     ]
    }
   ],
   "source": [
    "# Apply SVM !!! - binary classifier - trained to identify the presence or absence of a particular attribute\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( img_arr, white, test_size=0.33, random_state=42)\n",
    "\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "# clf = svm.SVC(kernel='rbf')\n",
    "print(\"yupzie\")\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply CNN \n",
    "\n",
    "CNNclf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "CNNclf = CNNclf.fit(X_train,y_train)\n",
    "\n",
    "cnny_predict = CNNclf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,cnny_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results - cropped dataset - considering complete image \n",
    "\n",
    "# Attribute    SVM         CNN      SVM- Half_face  SVM_HaarCascades\n",
    "\n",
    "# NoEyeWear   0.777.       0.722      0.84             0.91          --- 93.5   \n",
    "# White       0.69         0.72       0.71             0.699         --- 91.3  --- 72.4\n",
    "# Sunglasses  0.97         0.97       0.977            0.95          --- 94.91\n",
    "# smiling     0.55         0.79       0.821            0.883         --- 95.33 --- 95.33\n",
    "# v_forehead. 0.72         0.74       0.85             0.85          --- 89.43 --- 93.10\n",
    "# No beard    0.81         0.832      0.88             0.88          --- 89.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TODO - \n",
    "\n",
    "find online available codes on attribute classification\n",
    "\n",
    "Run the same code on the complete dataset\n",
    "\n",
    "read the paper richa maam sent \n",
    "\n",
    "compare the results.\n",
    "\n",
    "read the paper richa maan sebt by the sine\n",
    "# Paper implemtnation is not supposed to be done\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
