{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BTP_10thApr.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/aksh98/Attribute_Classification/blob/master/BTP_10thApr.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "zu-vuLiuEpW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "3e83f765-277b-48fb-b127-d51e2b1f35b5"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PeJtDVi6E5kE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9T9i5lmLI7q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7bf7ff52-ed7e-43c1-d937-e92b7d01bfe8"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\r\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ltPsvD1LiYo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrqeOgkbLmaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65058b8e-c7b9-49e0-cdae-4125a282a680"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import scipy.io\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.colors import Normalize\n",
        "import os\n",
        "import pickle\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.utils as vutil\n",
        "import argparse\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "from argparse import ArgumentParser\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(\"Done\")\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_l0HidBvLxPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f9631173-ae49-4f8f-af7c-021d16783389"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "%cd drive\n",
        "%cd Colab Notebooks \n",
        "#/content/drive/Colab Notebooks\n",
        "# !jar xvf btpaligned2.zip \n",
        "!ls"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive'\n",
            "/content/drive/Colab Notebooks\n",
            "[Errno 2] No such file or directory: 'Colab Notebooks'\n",
            "/content/drive/Colab Notebooks\n",
            "BTP_10thApr.ipynb\t  btpattributesrefined.csv.ods\tIP.ipynb\n",
            "BTP1.ipynb\t\t  btpdataset.txt\t\tlfw_aligned\n",
            "btpaligned2\t\t  btpfinalattributes.csv\tlfwcolorfaces.zip\n",
            "btpaligned2.zip\t\t  BTP.ipynb\t\t\tlfw_crop_A\n",
            "btpaligned.zip\t\t  finallala.txt\t\t\t__MACOSX\n",
            "BTPattributefile.csv\t  full_attributes.txt\t\tUntitled0.ipynb\n",
            "BTP_Attributes.ods\t  imgarr_3513.pkl\t\tUntitled1.ipynb\n",
            "btpattributesrefined.csv  imgarr_3788.pkl\t\tUntitled2.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kQ-g6KJL3xSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e087382e-af6b-439c-9a54-9f0b158d0c10"
      },
      "cell_type": "code",
      "source": [
        "%cd drive/Colab Notebooks/lfw_aligned\n",
        "!ls -l | wc -1\n",
        "%cd .."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Colab Notebooks/lfw_aligned\n",
            "  13234  119099  867436\n",
            "/content/drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0i_gnuNi6bBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "c241a3a4-9ace-4216-b328-9f664bb49979"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(description='Process some integers.')\n",
        "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
        "                    help='input batch size for training (default: 64)')\n",
        "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
        "                    help='input batch size for testing (default: 1000)')\n",
        "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
        "                    help='number of epochs to train (default: 10)')\n",
        "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
        "                    help='learning rate (default: 0.01)')\n",
        "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
        "                    help='SGD momentum (default: 0.5)')\n",
        "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                    help='disables CUDA training')\n",
        "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                    help='random seed (default: 1)')\n",
        "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
        "                    help='how many batches to wait before logging training status')\n",
        "args = parser.parse_args()\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--batch-size N] [--test-batch-size N]\n",
            "                             [--epochs N] [--lr LR] [--momentum M] [--no-cuda]\n",
            "                             [--seed S] [--log-interval N]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /content/.local/share/jupyter/runtime/kernel-3c5b9fb7-9e86-4229-bda8-150f4b6fd12c.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "na47TsZm7pHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dee6445b-9bf3-4f4a-9f50-bffc58b89cba"
      },
      "cell_type": "code",
      "source": [
        "# kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
        "\n",
        "mini_batch_size = 64\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(227),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) ])\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader('lfw_aligned', transform, batch_size = 64, shuffle=False)\n",
        "# test_loader = torch.utils.data.DataLoader('lfw_aligned', transform, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "      \n",
        "def readcsv(filename):\n",
        "    ifile = open(filename, \"rU\")\n",
        "    reader = csv.reader(ifile, delimiter=\",\")\n",
        "    rownum = 0\n",
        "    a = []\n",
        "\n",
        "    for row in reader:\n",
        "        a.append (row)\n",
        "        rownum += 1\n",
        "    \n",
        "    ifile.close()\n",
        "    return a\n",
        "\n",
        "# attributes = pd.read_csv('BTPattributefile.csv')\n",
        "# n = 65\n",
        "# print(len(attributes))\n",
        "# attrbutes = []\n",
        "# for i in range(0,13144):\n",
        "#     img_name = attributes.iloc[i, 0]\n",
        "#     landmarks = attributes.iloc[i, 2:].as_matrix()\n",
        "#     attributes.append()\n",
        "\n",
        "x = np.loadtxt('finallala.txt',delimiter = '\\n',dtype=np.str)\n",
        "print(len(x))\n",
        "array = []\n",
        "# h,w = 3513,41\n",
        "h, w = 3788, 41\n",
        "# h, w = 13143, 41 \n",
        "matrix = [[0 for x in range(w)] for y in range(h)] \n",
        "images = []\n",
        "# print(images)\n",
        "#---------------------\n",
        "# we have 74 attributes - and 2 for the name of the person\n",
        "for i in range(1,h):\n",
        "    arr = x[i].split() # 76 = len(arr)\n",
        "    name_len = len(arr)-41\n",
        "# Adding name to matrix\n",
        "    la = arr[0]+\"_\"\n",
        "    for l in range(1,name_len-1):\n",
        "        la += arr[l]+\"_\"\n",
        "#     print(arr[name_len-1])\n",
        "    if(float(arr[name_len-1]) > 99):\n",
        "        la += \"0\" + arr[name_len-1]+\".jpg\"\n",
        "    if(float(arr[name_len-1]) > 9 and float(arr[name_len]) < 100):\n",
        "        la += \"00\" + arr[name_len-1] +\".jpg\"    \n",
        "    if(float(arr[name_len-1]) < 10):\n",
        "        la += \"000\" + arr[name_len-1] +\".jpg\"\n",
        "#     matrix[i-1][0] = la\n",
        "    images.append(la)\n",
        "    \n",
        "    for j in range(name_len-1,len(arr)-1):\n",
        "#         if(float(arr[j+1]) > 0): \n",
        "#           matrix[i-1][j-name_len+1] = 1\n",
        "        matrix[i-1][j-name_len+1] = arr[j+1]\n",
        "#         else: \n",
        "#           matrix[i-1][j-name_len+1] = 0\n",
        "#         insertion(arr,j+1)\n",
        "print(\"Matrix size\",len(matrix),len(matrix[0]))\n",
        "# for i in range(0,41):\n",
        "#     print(matrix[0][i],\"-\",i,\"-\")"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13144\n",
            "Matrix size 3788 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "il7E7I0xsnzn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def insertion(arr,i):\n",
        "    if(float(arr[i]) > 0):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def out(i):\n",
        "    if(float(i) > 0):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BsyQp_edAPDV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# img_arr = []\n",
        "# i = 0\n",
        "# for i in range(0,13143): # 523 in this case\n",
        "#     img = images[i]\n",
        "#     imgpath = os.path.join(\"lfw_aligned/\",img)\n",
        "#     image = cv2.imread(imgpath)\n",
        "#   # print(np.shape(image))\n",
        "#     if(image is None):\n",
        "#         print(\"No Image loaded\")\n",
        "#         print(img)\n",
        "#     else:\n",
        "#         img_arr.append(np.reshape(image,62500*3))\n",
        "#     mat = matrix[i][:]\n",
        "#     sample = {'image': image, 'att': mat}\n",
        "#     i = i+1\n",
        "#     if(i%100 == 0):\n",
        "#         print(i,end=\" \")\n",
        "# # print(len(matrix[i]))\n",
        "# print(len(img_arr))\n",
        "\n",
        "# # img_arr(1,62500) and matrix(13143,74)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3dGxpvoz-1PA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(len(img_arr), len(img_arr[0]))\n",
        "# print(img_arr[2280][:])\n",
        "# print(mydict)\n",
        "# f = open('imgarr_3788.pkl', 'rb')\n",
        "# mydict = pickle.load(f)\n",
        "# print(len(mydict))\n",
        "# pickle.load(\"imgarr_3788.pkl\")\n",
        "# pickle.dump(img_arr,open(\"imgarr_3788.pkl\",\"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvlrJOeUKb3y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "17a30d6c-4f5f-48c0-edcf-33074bbe9781"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( mydict, matrix, test_size=0.33, random_state=44)\n",
        "print(len(X_train),len(X_train[0]))\n",
        "print(len(y_train),len(y_train[0]))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2537 187500\n",
            "2537 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qWjamSbA2ty9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cac5b3ff-b626-43b2-a8d1-f9f0ffe7b354"
      },
      "cell_type": "code",
      "source": [
        "# input image size = 227*227 - 250*250\n",
        "# ==============================================================\n",
        "# ==============================================================\n",
        "\n",
        "class InceptionB(nn.Module):\n",
        "    def __init__(self,in_channels):\n",
        "        super(InceptionB,self).__init__()\n",
        "        # Around Hair\n",
        "        self.fco_11 = nn.Linear(in_channels,512)\n",
        "        self.fco_12 = nn.Linear(512,512)\n",
        "        self.fco_13 = nn.Linear(512,13)\n",
        "\n",
        "        # Facial Hair\n",
        "        self.fco_21 = nn.Linear(in_channels,512)\n",
        "        self.fco_22 = nn.Linear(512,512)\n",
        "        self.fco_23 = nn.Linear(512,5)\n",
        "\n",
        "        # Cheeks\n",
        "        self.fco_31 = nn.Linear(in_channels,512)\n",
        "        self.fco_32 = nn.Linear(512,512)\n",
        "        self.fco_33 = nn.Linear(512,2)\n",
        "\n",
        "        # Fat\n",
        "        self.fco_41 = nn.Linear(in_channels,512)\n",
        "        self.fco_42 = nn.Linear(512,512)\n",
        "        self.fco_43 = nn.Linear(512,2)\n",
        "\n",
        "        \n",
        "    def forward(self,x):\n",
        "        br1 = F.relu(self.fco_11(x))\n",
        "        br1 = F.dropout(br1,p=0.5)\n",
        "        br1 = F.relu(self.fco_12(br1))\n",
        "        br1 = F.dropout(br1,p=0.5)\n",
        "        br1 = self.fco_13(br1)\n",
        "        \n",
        "        br2 = F.relu(self.fco_21(x))\n",
        "        br2 = F.dropout(br2,p=0.5)\n",
        "        br2 = F.relu(self.fco_22(br2))\n",
        "        br2 = F.dropout(br2,p=0.5)\n",
        "        br2 = self.fco_23(br2)\n",
        "        \n",
        "        br3 = F.relu(self.fco_31(x))\n",
        "        br3 = F.dropout(br3,p=0.5)\n",
        "        br3 = F.relu(self.fco_32(br3))\n",
        "        br3 = F.dropout(br3,p=0.5)\n",
        "        br3 = self.fco_33(br3)\n",
        "        \n",
        "        br4 = F.relu(self.fco_41(x))\n",
        "        br4 = F.dropout(br4,p=0.5)\n",
        "        br4 = F.relu(self.fco_42(br4))\n",
        "        br4 = F.dropout(br4,p=0.5)\n",
        "        br4 = self.fco_43(br4)\n",
        "        \n",
        "        output = [br1,br2,br3,br4]\n",
        "#         print(\"out ss- \",output)\n",
        "#         print(\"len ss- \",len(output))\n",
        "\n",
        "        return torch.cat(output,1)\n",
        "\n",
        "# ==============================================================\n",
        "# ==============================================================\n",
        "\n",
        "\n",
        "class InceptionA(nn.Module):\n",
        "    \n",
        "    def __init__(self,in_channels):  \n",
        "        super(InceptionA, self).__init__()\n",
        "        channel = 4800\n",
        "        # Gender\n",
        "        self.conv3g = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        # relu - 5*5 pooling - 5*5 normalization\n",
        "        self.fc1g = nn.Linear(channel,512)\n",
        "        self.fc2g = nn.Linear(512,512)\n",
        "        self.fc3g = nn.Linear(512,1)\n",
        "        \n",
        "        # Eyes \n",
        "        self.conv3e = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.fc1e = nn.Linear(channel,512)\n",
        "        self.fc2e = nn.Linear(512,512)\n",
        "        self.fc3e = nn.Linear(512,5)\n",
        "\n",
        "        # Nose\n",
        "        self.conv3n = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.fc1n = nn.Linear(channel,512)\n",
        "        self.fc2n = nn.Linear(512,512)\n",
        "        self.fc3n = nn.Linear(512,2)\n",
        "\n",
        "        # Face\n",
        "        self.conv3f = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.fc1f = nn.Linear(channel,512)\n",
        "        self.fc2f = nn.Linear(512,512)\n",
        "        self.fc3f = nn.Linear(512,6)\n",
        "\n",
        "        # Mouth \n",
        "        self.conv3m = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.fc1m = nn.Linear(channel,512)\n",
        "        self.fc2m = nn.Linear(512,512)\n",
        "        self.fc3m = nn.Linear(512,4)\n",
        "\n",
        "        # Others\n",
        "        self.conv3o = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.others = InceptionB(channel)\n",
        "        \n",
        "        \n",
        "    def forward(self,x):\n",
        "        b1 = F.relu(self.conv3g(x))\n",
        "        b1 = F.max_pool2d(b1, kernel_size=5)\n",
        "        b1 = b1.view(1,4800)\n",
        "        b1 = F.relu(self.fc1g(b1))\n",
        "        b1 = F.dropout(b1,p=0.5)\n",
        "        b1 = F.relu(self.fc2g(b1))\n",
        "        b1 = F.dropout(b1,p=0.5)\n",
        "        b1 = self.fc3g(b1)\n",
        "        \n",
        "        b2 = F.relu(self.conv3e(x))\n",
        "        b2 = F.max_pool2d(b2, kernel_size=5)\n",
        "        b2 = b2.view(1,4800)\n",
        "        b2 = F.relu(self.fc1e(b2))\n",
        "        b2 = F.dropout(b2,p=0.5)\n",
        "        b2 = F.relu(self.fc2e(b2))\n",
        "        b2 = F.dropout(b2,p=0.5)\n",
        "        b2 = self.fc3e(b2)\n",
        "        \n",
        "        b3 = F.relu(self.conv3n(x))\n",
        "        b3 = F.max_pool2d(b3, kernel_size=5)\n",
        "        b3 = b3.view(1,4800)\n",
        "        b3 = F.relu(self.fc1n(b3))\n",
        "        b3 = F.dropout(b3,p=0.5)\n",
        "        b3 = F.relu(self.fc2n(b3))\n",
        "        b3 = F.dropout(b3,p=0.5)\n",
        "        b3 = self.fc3n(b3)\n",
        "        \n",
        "        b4 = F.relu(self.conv3f(x))\n",
        "        b4 = F.max_pool2d(b4, kernel_size=5)\n",
        "        b4 = b4.view(1,4800)\n",
        "        b4 = F.relu(self.fc1f(b4))\n",
        "        b4 = F.dropout(b4,p=0.5)\n",
        "        b4 = F.relu(self.fc2f(b4))\n",
        "        b4 = F.dropout(b4,p=0.5)\n",
        "        b4 = self.fc3f(b4)\n",
        "        \n",
        "        b5 = F.relu(self.conv3m(x))\n",
        "        b5 = F.max_pool2d(b5, kernel_size=5)\n",
        "        b5 = b5.view(1,4800)\n",
        "        b5 = F.relu(self.fc1m(b5))\n",
        "        b5 = F.dropout(b5,p=0.5)\n",
        "        b5 = F.relu(self.fc2m(b5))\n",
        "        b5 = F.dropout(b5,p=0.5)\n",
        "        b5 = self.fc3m(b5)\n",
        "        \n",
        "        b6 = F.relu(self.conv3o(x))\n",
        "        b6 = F.max_pool2d(b6, kernel_size=5)\n",
        "        b6 = b6.view(1,4800)\n",
        "        b6 = self.others(b6)\n",
        "        \n",
        "        outputs = [b1,b2,b3,b4,b5,b6] # + b6\n",
        "#         print(\"out - \",outputs)\n",
        "#         print(\"len - \",len(outputs))\n",
        "        \n",
        "        return torch.cat(outputs,1)\n",
        "        \n",
        "# ==============================================================\n",
        "# ==============================================================\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # relu - 3*3 max pooling - 5*5 normalization\n",
        "        self.conv1 = nn.Conv2d(3, 75, kernel_size = 7)\n",
        "        \n",
        "        # relu - 3*3 pooling - 5*5 normalization\n",
        "        self.conv2 = nn.Conv2d(75, 200, kernel_size = 5)\n",
        "#         nn.BatchNorm2d(5*5)\n",
        "        # inception in_channels = 200\n",
        "        self.incept = InceptionA(in_channels = 200)\n",
        "        self.fcaux = nn.Linear(40,40)\n",
        "    \n",
        "    def forward(self, x):\n",
        "#         print(x.size(0))\n",
        "        in_size = x.size(0)\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),(3,3))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)),(3,3))\n",
        "        x = self.incept(x)\n",
        "        x = self.fcaux(x)\n",
        "#         print(x.shape())\n",
        "        return x\n",
        " \n",
        "# net = Net()\n",
        "# net.cuda\n",
        "model = Net()\n",
        "model = model.double()\n",
        "# print(model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    batch_idx = 0\n",
        "#     print(len(X_train),len(X_train[0]),len(y_train))\n",
        "    for (data, target) in zip(X_train,y_train):\n",
        "        batch_idx = batch_idx+1\n",
        "        target = torch.from_numpy(np.array(target,dtype='double')).double()\n",
        "        data = torch.from_numpy(np.array(data,dtype='double')).double()\n",
        "        data, target = Variable((data),requires_grad=True), Variable((target),requires_grad=True)\n",
        "#         if args.cuda:\n",
        "#             data, target = data.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        data = data.view(1,3,250,250)\n",
        "        output = model(data)\n",
        "        i = 0\n",
        "        loss_seq = []\n",
        "        output = output.view(40,-1)\n",
        "        out = output.data.numpy()\n",
        "        tar = target.data.numpy()\n",
        "#         out = (out > 0).astype(np.int_)\n",
        "#         tar = (tar > 0).astype(np.int_)\n",
        "        for o in out:\n",
        "            if(i == 17):\n",
        "#                 currloss = min(criterion(o,target[i]),criterion(o,target[i]))\n",
        "#                 print(\"curr - \",currloss, \" i - \", i, criterion(o),target[i]),criterion(o,target[i+1])\n",
        "                currloss = min(abs((o-tar[i+1])*(o-tar[i+1])),abs((o-tar[i])*(o-tar[i])))\n",
        "                i = i+2\n",
        "            else:\n",
        "#                 currloss = criterion(o,target[i])\n",
        "#                 print(\"curr.. - \",currloss, \" i.. - \", i )\n",
        "                currloss = abs((o-tar[i])*(o-tar[i]))\n",
        "                i = i+1\n",
        "            loss_seq.append(currloss)\n",
        "      \n",
        "        loss = sum(loss_seq)/40\n",
        "        loss = torch.from_numpy(loss)\n",
        "        output = torch.from_numpy(out)\n",
        "        target = torch.from_numpy(tar)\n",
        "        loss = Variable(loss,requires_grad=True).double()\n",
        "        output = Variable(output,requires_grad=True).double()\n",
        "        target = Variable(target,requires_grad=True).double()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if(batch_idx % 100 == 0):\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(y_train),\n",
        "                100. * batch_idx / len(y_train), loss.data[0]))\n",
        "            \n",
        "def mse_loss(input, target):\n",
        "    return torch.sum((input - target)**2) / input.data.nelement()\n",
        "  \n",
        "def test():\n",
        "    model.eval()\n",
        "    batch_idx = 0\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for data, target in zip(X_test,y_test):\n",
        "        target = torch.from_numpy(np.array(target,dtype='double')).double()\n",
        "        data = torch.from_numpy(np.array(data,dtype='double')).double()\n",
        "        data, target = Variable(data, volatile=True), Variable(target,requires_grad=True)\n",
        "        \n",
        "        data = data.view(1,3,250,250)\n",
        "        loss_seq = []\n",
        "        output = model(data)\n",
        "        i = 0\n",
        "        temp = 0\n",
        "        output = output.view(40,-1)\n",
        "        out = output.data.numpy()\n",
        "        tar = target.data.numpy()        \n",
        "        # sum up batch loss\n",
        "        for o in out:\n",
        "            if(i == 17):\n",
        "#                 currloss = min(F.nll_loss(o,target(i+3)),F.nll_loss(o,target[i+2]))\n",
        "#                   currloss = min(criterion(o,target[i]),criterion(o,target[i+1]))\n",
        "                currloss = min(abs((o-tar[i+1])*(o-tar[i+1])),abs((o-tar[i])*(o-tar[i])))\n",
        "                if(np.sign(o)==np.sign(tar[i+1]) or np.sign(o) == np.sign(tar[i])):\n",
        "                    correct += 1\n",
        "                i = i+2\n",
        "      \n",
        "            else:\n",
        "#                 currloss = F.nll_loss(o,target[i+2])\n",
        "#                 currloss = criterion(o,target[i])\n",
        "                currloss = abs((o-tar[i])*(o-tar[i]))\n",
        "                if(np.sign(o)== np.sign(tar[i])):\n",
        "                    correct += 1\n",
        "                i = i+1\n",
        "                \n",
        "            loss_seq.append(currloss)\n",
        "        test_loss += sum(currloss)/40\n",
        "            \n",
        "        output = torch.from_numpy(out)\n",
        "        target = torch.from_numpy(tar)\n",
        "#         loss = Variable(loss,requires_grad=True).double()\n",
        "        output = Variable(output,requires_grad=True).double()\n",
        "        target = Variable(target,requires_grad=True).double()\n",
        "        \n",
        "#         test_loss = torch.nn.MSELoss(size_average=False)\n",
        "        # get the index of the max log-probability\n",
        "#         pred = output.data.max(1, keepdim=True)[1]\n",
        "#         correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(y_test)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(y_test), 100. * correct / len(y_test)))\n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [100/2537 (4%)]\tLoss: 1.640738\n",
            "Train Epoch: 1 [200/2537 (8%)]\tLoss: 1.991647\n",
            "Train Epoch: 1 [300/2537 (12%)]\tLoss: 2.174815\n",
            "Train Epoch: 1 [400/2537 (16%)]\tLoss: 2.298650\n",
            "Train Epoch: 1 [500/2537 (20%)]\tLoss: 2.047033\n",
            "Train Epoch: 1 [600/2537 (24%)]\tLoss: 2.684283\n",
            "Train Epoch: 1 [700/2537 (28%)]\tLoss: 2.164040\n",
            "Train Epoch: 1 [800/2537 (32%)]\tLoss: 2.758593\n",
            "Train Epoch: 1 [900/2537 (35%)]\tLoss: 2.776653\n",
            "Train Epoch: 1 [1000/2537 (39%)]\tLoss: 2.016087\n",
            "Train Epoch: 1 [1100/2537 (43%)]\tLoss: 2.484165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9oTdjwttIB52",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1 300 4 13 - br1 |  \n",
        "1 300 4 5  - br2 |\n",
        "1 300 4 2  - br3 |\n",
        "1 300 4 2  - br4\n",
        "\n",
        "br len = 4\n",
        "\n",
        "---\n",
        "\n",
        "1x300x4x1\n",
        "1x300x4x5\n",
        "1x300x4x2\n",
        "1x300x4x6\n",
        "1x300x4x4\n",
        "1x300x4x22"
      ]
    },
    {
      "metadata": {
        "id": "CNOYeXO9Brwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}