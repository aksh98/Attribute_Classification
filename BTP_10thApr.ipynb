{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BTP_10thApr.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/aksh98/Attribute_Classification/blob/master/BTP_10thApr.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "zu-vuLiuEpW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "58e9d16c-913c-4fb5-a753-9194eb0ec273"
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl \n",
        "!pip3 install torch\n",
        "!pip3 install torchvision\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==0.3.0.post4 from http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch->torchvision)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PeJtDVi6E5kE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1031
        },
        "outputId": "096bea68-a735-49e3-a763-f9b48114ce71"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gpg: keybox '/tmp/tmpjcmop_x5/pubring.gpg' created\n",
            "gpg: /tmp/tmpjcmop_x5/trustdb.gpg: trustdb created\n",
            "gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-75a4d519ca25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mvcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "9T9i5lmLI7q7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c929aa4b-89ff-4475-cb8d-ba3d059a197e"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fuse: mountpoint is not empty\r\n",
            "fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ltPsvD1LiYo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PrqeOgkbLmaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cce37b9b-8944-4035-d3d1-c8e4b9150256"
      },
      "cell_type": "code",
      "source": [
        "# ========================================================\n",
        "\n",
        "# State of the art Accuracy - 91.25\n",
        "\n",
        "# ========================================================\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import scipy.io\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from matplotlib.colors import Normalize\n",
        "import os\n",
        "import pickle\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.utils as vutil\n",
        "import argparse\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "from argparse import ArgumentParser\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(\"Done\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_l0HidBvLxPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a71dd55f-2704-4dcd-8ccf-52dd9ced015a"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "%cd drive\n",
        "%cd Colab Notebooks \n",
        "#/content/drive/Colab Notebooks\n",
        "# !jar xvf btpaligned2.zip \n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content/drive/Colab Notebooks\n",
            "BTP_10thApr.ipynb\t      btpfinalattributes.csv  __MACOSX\n",
            "BTP1.ipynb\t\t      BTP.ipynb\t\t      output1.txt\n",
            "btpaligned2\t\t      finallala.txt\t      output22.txt\n",
            "btpaligned2.zip\t\t      full_attributes.txt     output2.txt\n",
            "btpaligned.zip\t\t      imgarr_3513.pkl\t      output.txt\n",
            "BTPattributefile.csv\t      imgarr_3788.pkl\t      Untitled0.ipynb\n",
            "BTP_Attributes.ods\t      IP.ipynb\t\t      Untitled1.ipynb\n",
            "btpattributesrefined.csv      lfw_aligned\t      Untitled2.ipynb\n",
            "btpattributesrefined.csv.ods  lfwcolorfaces.zip\n",
            "btpdataset.txt\t\t      lfw_crop_A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kQ-g6KJL3xSJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd drive\n",
        "%cd Colab Notebooks\n",
        "# !ls -l | wc -l\n",
        "# %cd .\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0i_gnuNi6bBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "76494dec-c34c-495c-cbcd-6000c8e4af06"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "parser = argparse.ArgumentParser(description='Process some integers.')\n",
        "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
        "                    help='input batch size for training (default: 64)')\n",
        "parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
        "                    help='input batch size for testing (default: 1000)')\n",
        "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
        "                    help='number of epochs to train (default: 10)')\n",
        "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
        "                    help='learning rate (default: 0.01)')\n",
        "parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
        "                    help='SGD momentum (default: 0.5)')\n",
        "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                    help='disables CUDA training')\n",
        "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                    help='random seed (default: 1)')\n",
        "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
        "                    help='how many batches to wait before logging training status')\n",
        "args = parser.parse_args()\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--batch-size N] [--test-batch-size N]\n",
            "                             [--epochs N] [--lr LR] [--momentum M] [--no-cuda]\n",
            "                             [--seed S] [--log-interval N]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /content/.local/share/jupyter/runtime/kernel-ec9df0ab-0b8f-40de-9546-135bc18899bb.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "na47TsZm7pHj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "2cf777b8-f8d3-475a-b994-1c16424a316b"
      },
      "cell_type": "code",
      "source": [
        "# kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
        "print (\"her\")\n",
        "mini_batch_size = 64\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.CenterCrop(227),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) ])\n",
        "\n",
        "# train_loader = torch.utils.data.DataLoader('lfw_aligned', transform, batch_size = 64, shuffle=False)\n",
        "# test_loader = torch.utils.data.DataLoader('lfw_aligned', transform, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "      \n",
        "def readcsv(filename):\n",
        "    ifile = open(filename, \"rU\")\n",
        "    reader = csv.reader(ifile, delimiter=\",\")\n",
        "    rownum = 0\n",
        "    a = []\n",
        "\n",
        "    for row in reader:\n",
        "        a.append (row)\n",
        "        rownum += 1\n",
        "    \n",
        "    ifile.close()\n",
        "    return a\n",
        "\n",
        "# attributes = pd.read_csv('BTPattributefile.csv')\n",
        "# n = 65\n",
        "# print(len(attributes))\n",
        "# attrbutes = []\n",
        "# for i in range(0,13144):\n",
        "#     img_name = attributes.iloc[i, 0]\n",
        "#     landmarks = attributes.iloc[i, 2:].as_matrix()\n",
        "#     attributes.append()\n",
        "\n",
        "x = np.loadtxt('finallala.txt',delimiter = '\\n',dtype=np.str)\n",
        "print(len(x))\n",
        "array = []\n",
        "# h,w = 3513,41\n",
        "h, w = 3788, 41\n",
        "# h, w = 13143, 41 \n",
        "matrix = [[0 for x in range(w)] for y in range(h)] \n",
        "images = []\n",
        "# print(images)\n",
        "print (\"here\")\n",
        "#---------------------\n",
        "for i in range(1,h):\n",
        "    arr = x[i].split() # 76 = len(arr)\n",
        "    name_len = len(arr)-41\n",
        "# Adding name to matrix\n",
        "    la = arr[0]+\"_\"\n",
        "    for l in range(1,name_len-1):\n",
        "        la += arr[l]+\"_\"\n",
        "#     print(arr[name_len-1])\n",
        "    if(float(arr[name_len-1]) > 99):\n",
        "        la += \"0\" + arr[name_len-1]+\".jpg\"\n",
        "    elif(float(arr[name_len-1]) > 9 and float(arr[name_len]) < 100):\n",
        "        la += \"00\" + arr[name_len-1] +\".jpg\"    \n",
        "    elif(float(arr[name_len-1]) < 10):\n",
        "        la += \"000\" + arr[name_len-1] +\".jpg\"\n",
        "#     matrix[i-1][0] = la\n",
        "    images.append(la)\n",
        "    \n",
        "    for j in range(name_len-1,len(arr)-1):\n",
        "#         if(float(arr[j+1]) > 0): \n",
        "#           matrix[i-1][j-name_len+1] = 1\n",
        "        matrix[i-1][j-name_len+1] = arr[j+1]\n",
        "#         else: \n",
        "#           matrix[i-1][j-name_len+1] = 0\n",
        "#         insertion(arr,j+1)\n",
        "\n",
        "# matrix = np.matrix(matrix)\n",
        "\n",
        "print(\"Matrix size\",len(matrix),len(matrix[0]))\n",
        "\n",
        "# newmat = matrix.transpose()\n",
        "# for i in range(0,41):\n",
        "#     print(matrix[0][i],\"-\",i,\"-\")\n",
        "# print(\"Matrix size\",len(newmat),len(newmat[0]))\n",
        "\n",
        "# print (matrix.shape)\n",
        "# print (newmat.shape)\n",
        "# mo = np.min(matrix,axis = 0)\n",
        "# mo = np.min(newmat,axis = 1)\n",
        "\n",
        "# print(mo)\n",
        "\n",
        "# for i in range(0,41):\n",
        "#     for j in range(0,3788):\n",
        "#         normalized = ((newmat[i][j]-min(newmat[i]))/(max(newmat[i])-min((newmat[i]))))\n",
        "# # print(normalized.shape)\n",
        "# matrix = normalized.transpose()\n",
        "# for i in range(0,41):\n",
        "#     print(matrix[i][0],\"-\",i,\"-\")\n",
        "    "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "her\n",
            "13144\n",
            "here\n",
            "Matrix size 3788 1\n",
            "(3788, 41)\n",
            "(41, 3788)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-72df527e4f41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnewmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0mmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2415\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     return _methods._amin(a, axis=axis,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(self, axis, out)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \"\"\"\n\u001b[0;32m--> 809\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collapse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qgO47hYnKvfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18bc9c9a-2af7-4ba6-9a4d-0c007cde3116"
      },
      "cell_type": "code",
      "source": [
        "print (matrix.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3788, 41)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "il7E7I0xsnzn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def insertion(arr,i):\n",
        "    if(float(arr[i]) > 0):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def out(i):\n",
        "    if(float(i) > 0):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BsyQp_edAPDV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_arr = []\n",
        "i = 0\n",
        "for i in range(0,13143): # 523 in this case\n",
        "    img = images[i]\n",
        "    imgpath = os.path.join(\"lfw_aligned/\",img)\n",
        "    image = cv2.imread(imgpath)\n",
        "  # print(np.shape(image))\n",
        "    if(image is None):\n",
        "        print(\"No Image loaded\")\n",
        "        print(img)\n",
        "    else:\n",
        "        img_arr.append(np.reshape(image,62500*3))\n",
        "    mat = matrix[i][:]\n",
        "    sample = {'image': image, 'att': mat}\n",
        "    i = i+1\n",
        "    if(i%100 == 0):\n",
        "        print(i,end=\" \")\n",
        "# print(len(matrix[i]))\n",
        "print(len(img_arr))\n",
        "\n",
        "# img_arr(1,62500) and matrix(13143,74)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3dGxpvoz-1PA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "840b71e3-94f8-4f01-c329-af67f04677ff"
      },
      "cell_type": "code",
      "source": [
        "# print(len(img_arr), len(img_arr[0]))\n",
        "# print(img_arr[2280][:])\n",
        "# print(mydict)\n",
        "f = open('imgarr_3788.pkl', 'rb')\n",
        "mydict = pickle.load(f)\n",
        "# mydict = pickle.load(\"imgarr_3788.pkl\")\n",
        "print(len(mydict))\n",
        "# pickle.dump(img_arr,open(\"imgarr_3788.pkl\",\"wb\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zvlrJOeUKb3y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "955e73e7-38f9-4af7-fb29-f9778095577a"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "X_train, X_test, y_train, y_test = train_test_split( mydict, matrix, test_size=0.33, random_state=24)\n",
        "print(len(X_train),len(X_train[0]))\n",
        "print(len(y_train),len(y_train[0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2537 187500\n",
            "2537 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qWjamSbA2ty9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input image size = 227*227 - 250*250\n",
        "# ==============================================================\n",
        "# ==============================================================\n",
        "\n",
        "class InceptionB(nn.Module):\n",
        "    def __init__(self,in_channels):\n",
        "        super(InceptionB,self).__init__()\n",
        "        # Around Hair\n",
        "        self.fco_11 = nn.Linear(in_channels,512)\n",
        "        self.fco_12 = nn.Linear(512,512)\n",
        "        self.fco_13 = nn.Linear(512,13)\n",
        "\n",
        "        # Facial Hair\n",
        "        self.fco_21 = nn.Linear(in_channels,512)\n",
        "        self.fco_22 = nn.Linear(512,512)\n",
        "        self.fco_23 = nn.Linear(512,5)\n",
        "\n",
        "        # Cheeks\n",
        "        self.fco_31 = nn.Linear(in_channels,512)\n",
        "        self.fco_32 = nn.Linear(512,512)\n",
        "        self.fco_33 = nn.Linear(512,2)\n",
        "\n",
        "        # Fat\n",
        "        self.fco_41 = nn.Linear(in_channels,512)\n",
        "        self.fco_42 = nn.Linear(512,512)\n",
        "        self.fco_43 = nn.Linear(512,2)\n",
        "\n",
        "        \n",
        "    def forward(self,x):\n",
        "        br1 = F.relu(self.fco_11(x))\n",
        "        br1 = F.dropout(br1,p=0.5)\n",
        "        br1 = F.relu(self.fco_12(br1))\n",
        "        br1 = F.dropout(br1,p=0.5)\n",
        "        br1 = self.fco_13(br1)\n",
        "        \n",
        "        br2 = F.relu(self.fco_21(x))\n",
        "        br2 = F.dropout(br2,p=0.5)\n",
        "        br2 = F.relu(self.fco_22(br2))\n",
        "        br2 = F.dropout(br2,p=0.5)\n",
        "        br2 = self.fco_23(br2)\n",
        "        \n",
        "        br3 = F.relu(self.fco_31(x))\n",
        "        br3 = F.dropout(br3,p=0.5)\n",
        "        br3 = F.relu(self.fco_32(br3))\n",
        "        br3 = F.dropout(br3,p=0.5)\n",
        "        br3 = self.fco_33(br3)\n",
        "        \n",
        "        br4 = F.relu(self.fco_41(x))\n",
        "        br4 = F.dropout(br4,p=0.5)\n",
        "        br4 = F.relu(self.fco_42(br4))\n",
        "        br4 = F.dropout(br4,p=0.5)\n",
        "        br4 = self.fco_43(br4)\n",
        "        \n",
        "        output = [br1,br2,br3,br4]\n",
        "#         print(\"out ss- \",output)\n",
        "#         print(\"len ss- \",len(output))\n",
        "\n",
        "        return torch.cat(output,1)\n",
        "\n",
        "# ==============================================================\n",
        "# ==============================================================\n",
        "\n",
        "\n",
        "class InceptionA(nn.Module):\n",
        "    \n",
        "    def __init__(self,in_channels):  \n",
        "        super(InceptionA, self).__init__()\n",
        "        channel = 4800\n",
        "        # Gender\n",
        "        self.conv3g = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        # relu - 5*5 pooling - 5*5 normalization\n",
        "        self.fc1g = nn.Linear(channel,512)\n",
        "        self.fc2g = nn.Linear(512,512)\n",
        "        self.fc3g = nn.Linear(512,1)\n",
        "        \n",
        "        # Eyes \n",
        "        self.conv3e = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.fc1e = nn.Linear(channel,512)\n",
        "        self.fc2e = nn.Linear(512,512)\n",
        "        self.fc3e = nn.Linear(512,5)\n",
        "\n",
        "        # Nose\n",
        "        self.conv3n = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.fc1n = nn.Linear(channel,512)\n",
        "        self.fc2n = nn.Linear(512,512)\n",
        "        self.fc3n = nn.Linear(512,2)\n",
        "\n",
        "        # Face\n",
        "        self.conv3f = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.fc1f = nn.Linear(channel,512)\n",
        "        self.fc2f = nn.Linear(512,512)\n",
        "        self.fc3f = nn.Linear(512,6)\n",
        "\n",
        "        # Mouth \n",
        "        self.conv3m = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.fc1m = nn.Linear(channel,512)\n",
        "        self.fc2m = nn.Linear(512,512)\n",
        "        self.fc3m = nn.Linear(512,4)\n",
        "\n",
        "        # Others\n",
        "        self.conv3o = nn.Conv2d(in_channels, 300, kernel_size = 3)\n",
        "        self.others = InceptionB(channel)\n",
        "        \n",
        "        \n",
        "    def forward(self,x):\n",
        "        b1 = F.relu(self.conv3g(x))\n",
        "        b1 = F.max_pool2d(b1, kernel_size=5)\n",
        "        b1 = b1.view(1,4800)\n",
        "        b1 = F.relu(self.fc1g(b1))\n",
        "        b1 = F.dropout(b1,p=0.5)\n",
        "        b1 = F.relu(self.fc2g(b1))\n",
        "        b1 = F.dropout(b1,p=0.5)\n",
        "        b1 = self.fc3g(b1)\n",
        "        \n",
        "        b2 = F.relu(self.conv3e(x))\n",
        "        b2 = F.max_pool2d(b2, kernel_size=5)\n",
        "        b2 = b2.view(1,4800)\n",
        "        b2 = F.relu(self.fc1e(b2))\n",
        "        b2 = F.dropout(b2,p=0.5)\n",
        "        b2 = F.relu(self.fc2e(b2))\n",
        "        b2 = F.dropout(b2,p=0.5)\n",
        "        b2 = self.fc3e(b2)\n",
        "        \n",
        "        b3 = F.relu(self.conv3n(x))\n",
        "        b3 = F.max_pool2d(b3, kernel_size=5)\n",
        "        b3 = b3.view(1,4800)\n",
        "        b3 = F.relu(self.fc1n(b3))\n",
        "        b3 = F.dropout(b3,p=0.5)\n",
        "        b3 = F.relu(self.fc2n(b3))\n",
        "        b3 = F.dropout(b3,p=0.5)\n",
        "        b3 = self.fc3n(b3)\n",
        "        \n",
        "        b4 = F.relu(self.conv3f(x))\n",
        "        b4 = F.max_pool2d(b4, kernel_size=5)\n",
        "        b4 = b4.view(1,4800)\n",
        "        b4 = F.relu(self.fc1f(b4))\n",
        "        b4 = F.dropout(b4,p=0.5)\n",
        "        b4 = F.relu(self.fc2f(b4))\n",
        "        b4 = F.dropout(b4,p=0.5)\n",
        "        b4 = self.fc3f(b4)\n",
        "        \n",
        "        b5 = F.relu(self.conv3m(x))\n",
        "        b5 = F.max_pool2d(b5, kernel_size=5)\n",
        "        b5 = b5.view(1,4800)\n",
        "        b5 = F.relu(self.fc1m(b5))\n",
        "        b5 = F.dropout(b5,p=0.5)\n",
        "        b5 = F.relu(self.fc2m(b5))\n",
        "        b5 = F.dropout(b5,p=0.5)\n",
        "        b5 = self.fc3m(b5)\n",
        "        \n",
        "        b6 = F.relu(self.conv3o(x))\n",
        "        b6 = F.max_pool2d(b6, kernel_size=5)\n",
        "        b6 = b6.view(1,4800)\n",
        "        b6 = self.others(b6)\n",
        "        \n",
        "        outputs = [b1,b2,b3,b4,b5,b6] # + b6\n",
        "#         print(\"out - \",outputs)\n",
        "#         print(\"len - \",len(outputs))\n",
        "        \n",
        "        return torch.cat(outputs,1)\n",
        "        \n",
        "# ==============================================================\n",
        "# ==============================================================\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # relu - 3*3 max pooling - 5*5 normalization\n",
        "        self.conv1 = nn.Conv2d(3, 75, kernel_size = 7)\n",
        "        \n",
        "        # relu - 3*3 pooling - 5*5 normalization\n",
        "        self.conv2 = nn.Conv2d(75, 200, kernel_size = 5)\n",
        "#         nn.BatchNorm2d(5*5)\n",
        "        # inception in_channels = 200\n",
        "        self.incept = InceptionA(in_channels = 200)\n",
        "        self.fcaux = nn.Linear(40,40)\n",
        "    \n",
        "    def forward(self, x):\n",
        "#         print(x.size(0))\n",
        "        in_size = x.size(0)\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)),(3,3))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)),(3,3))\n",
        "        x = self.incept(x)\n",
        "        x = self.fcaux(x)\n",
        "#         print(x.shape())\n",
        "        return x\n",
        "\n",
        "file = open('output22.txt', 'w')\n",
        "# sys.stdout = file\n",
        "# net = Net()\n",
        "# net.cuda\n",
        "model = Net()\n",
        "model = model.double()\n",
        "print(model)\n",
        "# file.write(model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.5)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    batch_idx = 0\n",
        "#     print(len(X_train),len(X_train[0]),len(y_train))\n",
        "    for (data, target) in zip(X_train,y_train):\n",
        "        batch_idx = batch_idx+1\n",
        "        target = torch.from_numpy(np.array(target,dtype='double')).double()\n",
        "        data = torch.from_numpy(np.array(data,dtype='double')).double()\n",
        "        data, target = Variable((data),requires_grad=True), Variable((target),requires_grad=True)\n",
        "#         if args.cuda:\n",
        "#             data, target = data.cuda(), target.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        data = data.view(1,3,250,250)\n",
        "        output = model(data)\n",
        "        i = 0\n",
        "        loss_seq = []\n",
        "        output = output.view(40,-1)\n",
        "        out = output.data.numpy()\n",
        "        tar = target.data.numpy()\n",
        "#         out = (out > 0).astype(np.int_)\n",
        "#         tar = (tar > 0).astype(np.int_)\n",
        "        for o in out:\n",
        "            if(i == 17):\n",
        "#                 currloss = min(criterion(o,target[i]),criterion(o,target[i]))\n",
        "#                 print(\"curr - \",currloss, \" i - \", i, criterion(o),target[i]),criterion(o,target[i+1])\n",
        "                currloss = min(abs((o-tar[i+1])*(o-tar[i+1])),abs((o-tar[i])*(o-tar[i])))\n",
        "                i = i+2\n",
        "            else:\n",
        "#                 currloss = criterion(o,target[i])\n",
        "#                 print(\"curr.. - \",currloss, \" i.. - \", i )\n",
        "                currloss = abs((o-tar[i])*(o-tar[i]))\n",
        "                i = i+1\n",
        "            loss_seq.append(currloss)\n",
        "      \n",
        "        loss = sum(loss_seq)/40\n",
        "        loss = torch.from_numpy(loss)\n",
        "        output = torch.from_numpy(out)\n",
        "        target = torch.from_numpy(tar)\n",
        "        loss = Variable(loss,requires_grad=True).double()\n",
        "        output = Variable(output,requires_grad=True).double()\n",
        "        target = Variable(target,requires_grad=True).double()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if(batch_idx % 100 == 0):\n",
        "            file.write('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(y_train),\n",
        "                100. * batch_idx / len(y_train), loss.data[0]))\n",
        "            \n",
        "            print('  Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}   '.format(\n",
        "                epoch, batch_idx * len(data), len(y_train),\n",
        "                100. * batch_idx / len(y_train), loss.data[0]),'\\n')\n",
        "            \n",
        "def mse_loss(input, target):\n",
        "    return torch.sum((input - target)**2) / input.data.nelement()\n",
        "  \n",
        "def test():\n",
        "    model.eval()\n",
        "    batch_idx = 0\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    for data, target in zip(X_test,y_test):\n",
        "        target = torch.from_numpy(np.array(target,dtype='double')).double()\n",
        "        data = torch.from_numpy(np.array(data,dtype='double')).double()\n",
        "        data, target = Variable(data, volatile=True), Variable(target,requires_grad=True)\n",
        "        \n",
        "        data = data.view(1,3,250,250)\n",
        "        loss_seq = []\n",
        "        output = model(data)\n",
        "        i = 0\n",
        "        temp = 0\n",
        "        output = output.view(40,-1)\n",
        "        out = output.data.numpy()\n",
        "        tar = target.data.numpy()        \n",
        "        # sum up batch loss\n",
        "        corr = 0\n",
        "        for o in out:\n",
        "            if(i == 17):\n",
        "#                 currloss = min(F.nll_loss(o,target(i+3)),F.nll_loss(o,target[i+2]))\n",
        "#                   currloss = min(criterion(o,target[i]),criterion(o,target[i+1]))\n",
        "                currloss = min(abs((o-tar[i+1])*(o-tar[i+1])),abs((o-tar[i])*(o-tar[i])))\n",
        "                if(abs(o-tar[i+1]) < 0.6 or abs(o-tar[i])<0.6):\n",
        "                    correct += 1\n",
        "                i = i+2\n",
        "      \n",
        "            else:\n",
        "#                 currloss = F.nll_loss(o,target[i+2])\n",
        "#                 currloss = criterion(o,target[i])\n",
        "                currloss = abs((o-tar[i])*(o-tar[i]))\n",
        "                if((o-tar[i]) < 0.6):\n",
        "                    correct += 1\n",
        "                i = i+1\n",
        "                \n",
        "            loss_seq.append(currloss)\n",
        "        test_loss += sum(currloss)/40\n",
        "#         correct = correct + (corr/40)\n",
        "        output = torch.from_numpy(out)\n",
        "        target = torch.from_numpy(tar)\n",
        "#         loss = Variable(loss,requires_grad=True).double()\n",
        "        output = Variable(output,requires_grad=True).double()\n",
        "        target = Variable(target,requires_grad=True).double()\n",
        "        \n",
        "#         test_loss = torch.nn.MSELoss(size_average=False)\n",
        "        # get the index of the max log-probability\n",
        "#         pred = output.data.max(1, keepdim=True)[1]\n",
        "#         correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(y_test)\n",
        "    print('\\n Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%) \\n'.format(test_loss, correct, len(y_test), 100. * correct / len(y_test)*40))\n",
        "    file.write('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(y_test), 100. * correct / len(y_test)*40))\n",
        "\n",
        "for epoch in range(1, 5):\n",
        "    train(epoch)\n",
        "    test()\n",
        "file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9oTdjwttIB52",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1 300 4 13 - br1 |  \n",
        "1 300 4 5  - br2 |\n",
        "1 300 4 2  - br3 |\n",
        "1 300 4 2  - br4\n",
        "\n",
        "br len = 4\n",
        "\n",
        "---\n",
        "\n",
        "1x300x4x1\n",
        "1x300x4x5\n",
        "1x300x4x2\n",
        "1x300x4x6\n",
        "1x300x4x4\n",
        "1x300x4x22"
      ]
    },
    {
      "metadata": {
        "id": "CNOYeXO9Brwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}